## Abstract

Graph attention networks (GAT) have been state-of-the-art GNN architecture used as the backbone for various graph learning problems. One of the key tasks in graph learning is node classification. While several works cover multiple aspects of node classification, there has yet to be an attempt to understand the behavior of GAT models for node classification with a reject option. This paper proposes a new approach called Node-CwR, which models node classification with a re- ject option using GAT. We offer both cost-based and coverage-based models to include the reject option in the node classification task. Cost-based models find the optimal classifier for a given cost of rejection value. Such models are trained by minimizing the rejection and misclassification rates on unrejected samples. Coverage-based

## Introduction

The recent decade has witnessed a surge of interest in using graph neural networks (GNNs) in various domains such as computer vision Satorras & Estrach (2018), natural language process- ing Schlichtkrull et al. (2017), and bioinformatics Xia & Ku (2021), to name a few. GNNs (Kipf & Welling, 2017) capture structural aspects of the data in the form of nodes and edges to perform any prediction task. It learns node, edge, and graph-level embeddings to get high-dimensional fea- tures using the message-passing mechanism in the GNN layer. Recently, graph attention networks (GAT) (Veliˇckovi´c et al., 2018) have been shown to work well for node-level tasks as they leverage the attention mechanism to learn the importance of neighboring nodes and scale their features ac- cordingly before performing a linear combination of the nodes. The most common node-level task is a node classification task, which uses graph-structured data to classify nodes. Deep graph learning is also used in the field of responsible AI in high-risk applications such as legal judgment prediction Dong & Niu (2021), disease prediction Sun et al. (2021), financial fraud prediction Xu et al. (2021), etc., with the high cost of incorrect predictions. It is challenging to overcome such issues while using standard GNN architectures. To deal with such scenarios of high- risk applications, the model shouldn’t make a prediction and further examine the features instead of making a wrong prediction with potential consequences. Can we allow GNN models to abstain in case of insufficient confidence for prediction? Reject option classifiers have an additional option of refraining from deciding when in a dilemma. The attraction of reject option classification is evident in applications where one can afford partial domain coverage and where extremely low risk is a must. Still, it is not achievable in standard classification frameworks. Consider the case of the diagnosis of a patient for a specific disease. In case of confusion, the physician might choose not to risk misdiagnosing the patient. She might instead recommend further medical tests to the patient or refer her to an appropriate specialist. The primary response in these cases is to ”reject” the example. Typically, there is a cost involved in 1 Under review as a conference paper at ICLR 2024 rejecting an example. However, that cost is much smaller compared to misclassification. The goal of integrating a reject option in the classification model is to allow it to abstain from giving a prediction when it is highly uncertain to make a decision. These models are usually given the option not to make a prediction based on the following two ideas: i) Coverage-based model: Coverage is defined as the ratio of samples that the model does not reject. For a given coverage, the model finds the best examples that can give the best performance. The coverage can further be varied post-training by our choice of threshold. SelectiveNet (El-Yaniv et al., 2010; Geifman & El-Yaniv, 2019) is a recent work that proposes a coverage based deep neural network (DNN) approach for the reject option classifier. ii) Cost-based model: These models include the cost of rejection and misclassification. The cost of rejection can vary based on the application. The model optimizes according to the cost to minimize the number of examples rejected and misclassified. The loss in such approaches is l0d1 (Chow, 1970). However, in practice, surrogates of l0d1 (Bartlett & Wegkamp, 2008; Grandvalet et al., 2009; Manwani et al., 2015; Shah & Manwani, 2019; Cortes et al., 2016) are used. DNN- based reject option classifier are proposed in Kalra et al. (2021); Ni et al. (2019); Charoenphakdee et al. (2021); Cao et al. (2022). However, the reject option for the node classification problem using GNN has not been attempted. Motivated by the abovementioned observations, we propose rejection-based GAT networks for the node classification tasks, which we call NodeCwR. We consider an integrated reject option using cost-based (NodeCwR-Cost) and coverage-based (NodeCwR-Cov) models. We can use NodeCwR- Cost when the cost of rejecting an example and NodeCwR-Cov when the ratio of examples to predict is specified. We also explore label smoothing to see if NodeCwR becomes robust when there is label noise. Our contributions are as follows: i.) To the best of our knowledge, we are the first to learn node embeddings using abstention-based GAT architecture. ii.) We extend and generalize GAT to train for node features with cost-based and coverage-based abstention models. iii.) Finally, we per- form an empirical study to evaluate our models on popular benchmark datasets for node classifica- tion tasks. Our experimental results show that NodeCwR-Cost performs better than NodeCwR-Cov in general. iv.) We also show experimentally that NodeCwR-Cost with label smoothing becomes robust against label noise. 2 RELATED WORK 2.1 REJECT OPTION CLASSIFICATION There are two broad categories of approaches for reject option classifiers: coverage-based and cost-based. Coverage-based learn based on optimizing risk-coverage trade-offs. SelectiveNet is a coverage-based method proposed for learning with abstention (El-Yaniv et al., 2010; Geifman & El-Yaniv, 2019). SelectiveNet is a deep neural network architecture that optimizes prediction and selection functions to model a selective predictor. As this approach does not consider rejection cost d in their objective function, it can avoid rejecting hazardous examples. This, in particular, becomes a severe issue in high-risk situations (e.g., healthcare systems, etc.). Cost-based approaches assume that the reject option involves a cost d. Generalized hinge SVM (Bartlett & Wegkamp, 2008), dou- ble hinge SVM (Grandvalet et al., 2009), double ramp SVM (Manwani et al., 2015), SDR-SVM (Shah & Manwani, 2019), max-hinge SVM and plus-hinge SVM (Cortes et al., 2016) etc. are some variants of support vector machine (SVM) for reject option classifiers. Nonlinear classifiers in these approaches are learned using kernel functions. In (Kalra et al., 2021), the authors propose a deep neural network-based reject option classifier for two classes that learn instance-dependent rejection functions. In Ramaswamy et al. (2018), multiclass extensions of the hinge-loss with a confidence threshold are considered for reject option classification. Ni et al. (2019) prove calibration results for various confidence-based smooth losses for multiclass reject option classification. Charoenphakdee et al. (2021) prove that K-class reject option classification can be broken down into K binary cost- sensitive classification problems. They subsequently propose a family of surrogates, the ensembles of arbitrary binary classification losses. Cao et al. (2022) propose a general recipe to convert any multiclass loss function to accommodate the reject option, calibrated to loss l0d1. They treat rejec- tion as another class. 2 Under review as a conference paper at ICLR 2024 2.2 NODE CLASSIFICATION Node classification is a fundamental task related to machine learning for graphs and network anal- ysis. GNN methods can be broadly classified into three categories that perform node classification as the primary task. The first set of models introduced convolution-based GNN architectures by extending original CNNs to graphs Scarselli et al. (2008), Defferrard et al. (2016), Hamilton et al. (2017), Kipf & Welling (2017) Bresson & Laurent (2017). Secondly, proposed attention and gating mechanism-based architectures using anisotropic operations on graphs Veliˇckovi´c et al. (2018). The third category focuses on the theoretical limitations of previous types Xu et al. (2018), Morris et al. (2019), Maron et al. (2019), Chen et al. (2019). 2.3 LABEL SMOOTHING Label smoothing uses a positively weighted combination of hard training labels and uniformly dis- tributed soft labels. It was first proposed in Szegedy et al. (2016) for model regularization in the con- text of CNNs. When there are noisy labels, label smoothing is a robust learning approach (Lukasik et al., 2020). Wei et al. (2021) introduce the concept of negative label smoothing (NLS) in which soft labels for some classes can be negative. They show that NLS is more effective than simple label smoothing in case of a high noise rate. 3 METHOD GAT focuses on learning effective and efficient representations of nodes to perform any downstream task. Let X be the instance space and Y ∈ {1, . . . , K} be the label space. We represent the embedding space learned using GAT by H. Thus, GAT learns a mapping GAT : X → H. GAT treats each instance as a node and learns embedding for each node. 3.1 NODECWR-COV: COVERAGE BASED NODE CLASSIFIER WITH REJECTION NodeCwR-Cov uses coverage-based logic to learn node classifiers with a reject option. We use similar ideas to SelectiveNet (Geifman & El-Yaniv, 2019) to learn the coverage-based rejection function. Figure 1 shows the architecture of NodeCwR-Cov. Node representations are learned using first GAT layer and given as input to second GAT layer which follows softmax layer. The second GAT layer and softmax layer combined learn mapping f : H → ∆K−1 where ∆K−1 is K-dimensional simplex. Function f is used to predict the class of a node. There are two more fully connected layers after the softmax layer (having 512 nodes and one node) to model the selection function g : H → {0, 1}. Selection function g decides whether to predict a given example or not. Selection function g(h) is a single neuron with a sigmoid activation. At the beginning, a threshold of 0.5 is set for the selection function, which means f (h) predicts h if and only if g(h) ≥ 0.5. The auxiliary prediction head implements the prediction task a(h) without the need for coverage to get a better representation of examples with low confidence scores, which are usually ignored by the prediction head. This head is only used for training purposes. We use cross-entropy loss lce to capture the error made by the prediction function f (h). The empirical risk of the model is captured as follows. r(f , g|Sn) = (cid:80)n 1 n i=1 l(f (hi), yi)g(hi) ϕ(g|Sn) where ϕ(g|Sn) is empirical coverage computed as ϕ(g|Sn) = 1 i=1 g(hi). An optimal selec- n tive model could be trained by optimizing the selective risk given constant coverage. We use the following error function to optimize f (.) and g(.). (cid:80)n E(f , g) = r(f , g|Sn) + λΨ(c − ϕ(g|Sn)) where Ψ(a) = max(0, a)2 is a quadratic penalty function, c is the target coverage, and λ controls the importance of coverage constraint. The loss function used at the auxiliary head is standard cross entropy loss lce without any coverage constraint. Thus, the empirical risk function corresponding to the auxiliary head is E(f ) = 1/n (cid:80)n i=1 lce(f (hi), yi). The final error function of NodeCwR-Cov is a convex combination of E(f, g) and E(f ) as follows, E = αE(f , g) + (1 − α)E(f ), where α ∈ (0, 1). When the data is trained over a training set using a coverage constraint, this constraint 3 Under review as a conference paper at ICLR 2024 Figure 1: Architecture of NodeCwR-Cov: Coverage based node classifier with rejection is violated on the test set. The constraint requires the true coverage ϕ(g) to be larger than the given coverage constraint c, which is usually violated. To get the optimal actual coverage, we calibrate the threshold τ to select the example in g(h′) using this validation set, which results in coverage as close as possible to target coverage. 3.2 NODECWR-COST: COST BASED NODE CLASSIFIER WITH REJECTION In the cost-based method, the cost of rejection d is pre-specified. The architecture of NodeCwR- Cost is presented in Figure 2. The first block in NodeCwR-Cost consists of two GAT layers. The output of the second GAT layer is fed to a softmax layer with (K + 1) nodes. Note that we assume rejection as the (K + 1)th class here. The second GAT layer and softmax layer combined learn prediction function f : H → ∆K where ∆K is (K + 1)-dimensional simplex. Note that (K + 1)th output corresponds to the reject option in this architecture. Let ej denote K + 1-dimensional vector such that its jth element is one and other elements are zero. Note that (K + 1)th element never becomes one as we do not get a rejection label in the training data. We use the following variant of cross-entropy loss, which also incorporates the cost of rejection (Cao et al., 2022). ld ce(f (h), ey, eK+1) = lce(f (h), ey) + (1 − d)lce(f (h), eK+1) = − log fy(h) − (1 − d) log fK+1(h) Here fK+1(h) is the output corresponding to the reject option, and fy(h) is the output related to the actual class. For very small values of d, the model focuses more on maximizing fK+1(h) to prefer rejection over misclassification. Note that loss ld ce is shown to be consistent with the l0d1 loss (Cao et al., 2022). For d = 1, the loss ld ce becomes the same as standard cross entropy loss lce. We represent smooth label of j ∈ {1, . . . , K + 1} with a K + 1-dimensional vector eLS as j = (1 − ϵ)ej + ϵ eLS K+1 1. Here ϵ ∈ (0, 1) is the smoothing parameter, 1 is a K + 1-dimension vector whose all elements are one. ld j ce(f (h), eLS ld y , eLS K+1) = lce(f (h), eLS ce loss with smooth label is as follows. K+1) y ) + (1 − d)lce(f (h), eLS = (1 − ϵ)lce(f (h), ey) + (cid:20) (1 − ϵ)lce(f (h), eK+1) + + (1 − d) lce(f (h), 1) ϵ K + 1 (cid:21) lce(f (h), 1) ϵ K + 1 = (1 − ϵ)ld ce(f (h), ey, eK+1) + (2 − d)ϵ K + 1 lce(f (h), 1) Thus, we also do smoothing over (K + 1)th class which is rejection. We observe that this way of smoothing gives better performance in experiments. The extra term (2−d)ϵ K+1 lce(f (h), 1) acts as a ϵ K+1 1. regularizer which penalizes the model for going away from the uniform distribution 4 EXPERIMENTAL STUDY This section describes the implementation details of NodeCwR-Cost and NodeCwR-Cov, their per- formance evaluation, and their comparison. We also present results with label noise. 4 Under review as a conference paper at ICLR 2024 Figure 2: Architecture of NodeCwR-Cost: Cost based node classifier with rejection 4.1 DATATSETS USED We evaluated our model on three standard citation network datasets, Cora, Citeseer, and Pubmed (Sen et al., 2008). In these data sets, each document is represented by a node, and the class label represents the category of the document. Undirected edges represent citations. For training, we use 20 nodes per class. Thus, the number of nodes for training varies for each data set depending on the number of classes. We use 500 nodes for validation and 1000 for testing on all the data sets. 4.2 GAT IMPLEMENTATION DETAILS We used GAT as the base architecture for node classification and closely followed the experimental setup mentioned in Veliˇckovi´c et al. (2018). We modified the GAT implementation available by Antognini (2021) to implement our approach. We first applied dropout Srivastava et al. (2014) on node features with p = 0.6. These node features, along with the adjacency matrix, are passed through a GAT Layer having eight attention heads, where each head produces eight features per node. We used LeakyReLU as the activation function inside the GAT Layer with α = 0.2. These outputs are concatenated for the first layer (64 features per node). Another dropout layer with the same probability follows this. The dropout layer’s output is passed through the final GAT layer with a single attention head, which takes 64 features per node and outputs k features per node, where k is the number of classes. It uses ELU Clevert et al. (2015) activation function. The network output is passed through a softmax layer to get class posterior probabilities. 4.3 NODECWR-COV IMPLEMENTATION DETAILS We use the GAT architecture noted above to integrate the coverage-based reject option into the model as mentioned in Geifman & El-Yaniv (2019). The output from the softmax layer is separately given to both prediction head f and auxiliary head h. The output from the second GAT Layer is passed through a Fully Connected Hidden Layer with 512 nodes. This is passed through Batch Normalization Ioffe & Szegedy (2015), ReLU, and a Fully Connected Output Layer with one node. This is passed through Sigmoid Activation to get a selection score [0, 1]. The Prediction head and Selection head are concatenated together, and the selective loss is performed on this output. We set λ = 32 as the constraint on coverage to calculate this loss. Cross Entropy Loss is performed on the output of the Auxiliary head but is not used for making predictions. A convex combination of these two loss values with αl = 0.5 is used to optimize the model. We trained the model with early stopping with patience of 100 epochs. Error on the validation set is used to implement the stopping condition. We observed that the model trains for approximately 1800 epochs to train the NodeCwR-Cov model. Once the model is trained, the number of covered examples on the test data set when τ = 0.5 will vary highly because the model is not used for the test data. However, since we have the selection scores of each node, we sort them and select a τ value that matches the coverage we expect. 4.4 NODECWR-COST IMPLEMENTATION DETAILS We also trained NodeCwR-Cost by taking the output of the GAT network. In the cost-based ap- proach, we treat the reject option as an integrated class in the model. Hence, for a k class classifi- cation problem, we change the model architecture from giving k outputs to k + 1 outputs. In this 5 Under review as a conference paper at ICLR 2024 model, we have to perform CwR Loss for optimization. From the output, every node that gets k + 1 as the output will be rejected. Here also, we used early stopping with a patience of 100 epochs. Model trains for approximately 1000 epochs for NodeCwR-Cost. 4.5 RESULTS ON NODECWR-COV We repeat each experiment 10 times with random initialization and report the average and standard deviation. We see that the performance of NodeCwR-Cov decreases with label smoothing except for the Citeseer dataset. For the Citeseer dataset, for d=0.1,0.2,0.8,0.9 LS = ϵ dominates LS = 0. However, the gain is marginal. Cora Pubmed Citeseer Cov 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 Acc(LS=0) 97.8 ± 0.84 97.1 ± 0.77 96.43 ± 0.85 95.62 ± 1.16 93.96 ± 1.45 92.65 ± 0.5 91.29 ± 0.45 89.12 ± 0.8 86.65 ± 0.7 Acc(LS=0.5) Acc(LS=0) Acc(LS=0.5) Acc(LS=0) Acc(LS=0.5) 87.2 ± 5.36 96.13 ± 2.42 80.6 ± 12 94.75 ± 1.86 82.1 ± 3.81 93.33 ± 1.43 82.2 ± 2.23 92.38 ± 0.77 79.9 ± 2.47 92.18 ± 1.1 82.5 ± 1.87 91.29 ± 1.32 79.5 ± 0.98 90.25 ± 1.7 81 ± 0.44 88.5 ± 1.43 79 ± 1.17 85.81 ± 1.03 89 ± 4.42 87.5 ± 2.62 85.6 ± 2.5 85.2 ± 1.46 81.3 ± 2.19 79.6 ± 2.43 75.9 ± 2.86 72.8 ± 1.05 72 ± 0.69 89.2 ± 4.6 88.1 ± 1.92 84.7 ± 3.42 82.8 ± 3.44 76.6 ± 6.06 78.4 ± 4 74.8 ± 2.12 73.2 ± 2.29 74.3 ± 0.41 93.4 ± 2.61 80.4 ± 10.6 85.5 ± 3.49 85.3 ± 1.74 83.2 ± 3.34 82.6 ± 1.48 79.8 ± 2.46 80.9 ± 1.24 79.7 ± 0.59 Table 1: Accuracy and Coverage of GAT + CwR at different cost of rejection. Although we can calibrate the threshold to cover any number of examples irrespective of the training coverage, it is preferred to train the model on similar coverage rates and then calibrate it to our preferred coverage to get the best results. 4.6 RESULTS ON NODECWR-COST We repeat each experiment 10 times with random initialization and report the average and standard deviation. As the d increases, the rejection rate decreases, increasing coverage. As the coverage increases, more misclassifications happen, which decreases the accuracy. We observe this trend even with label smoothing. This behavior is expected from a cost-based rejection model. We observe that as the d increases, 0-d-1 risk increases initially, and it starts dropping after a certain value of d. These values of d are called crossover values. These crossover values are 0.55 for Cora, 0.45 for Pubmed, and 0.65 for Citeseer. For smaller values of d, when coverage increases, the misclassification rate also increases, which causes an increase in 0-d-1 risk. But, as d increases, the difference between misclassification cost (which is one) and rejection cost (d) reduces. We observe an interesting behavior of 0-d-1 risk, which favors LS = 0 (no label smoothing) for smaller d values and favors LS = ϵ (label smoothing) for higher values of d. This happens due to the following reasons. Label smoothing allows each label to exist with non-zero probability, for example. This creates more confusion areas for the classifier. This causes LS = ϵ to make more rejections for smaller d values than LS = 0. This makes LS = ϵ incur higher 0 − d − 1 risk than LS = 0 for smaller d values. For higher values of d, the rejection rate decreases for LS = ϵ and LS = 0. As d increases, coverage increases, and the NodeCwR-Cost approach focuses more on improving classification accuracy. At this point, the true power of LS = ϵ comes into the picture due to its regularization effect. Thus, NodeCwR-Cost with LS = ϵ starts performing better for higher d values than LS = 0. While we can calibrate the number of examples we want to predict in selection-based models, we can only choose a cost and let the model reject any examples in cost-based models. Hence, we plotted the accuracy with respect to the coverage of both these models for better comparison. 6 Under review as a conference paper at ICLR 2024 Acc. on d Unrejected 97.5 ± 0.48 0.1 97.5 ± 0.47 0.2 97.5 ± 0.68 0.3 96.6 ± 0.62 0.4 95.8 ± 0.23 0.5 95 ± 0.49 0.6 92.8 ± 0.55 0.7 90.1 ± 0.51 0.8 0.85 87.2 ± 0.78 97.4 ± 1.86 0.1 97.7 ± 2.49 0.2 93.5 ± 1.2 0.3 92.4 ± 0.66 0.4 88.9 ± 0.92 0.5 84.6 ± 0.87 0.6 - 0.1 100 0.2 99.2 ± 1.72 0.3 93.7 ± 2.26 0.4 91.6 ± 2.23 0.5 87.9 ± 0.88 0.6 85.5 ± 0.95 0.7 79.5 ± 0.72 0.8 0.83 75.8 ± 1.61 a r o C d e m b u P r e e s e t i C LS=0 Coverage 12.1 ± 0.95 17.1 ± 1.6 23.8 ± 1.75 32.2 ± 0.91 42.6 ± 1.88 53.1 ± 1.07 66.3 ± 1.81 83.3 ± 0.68 90.5 ± 1.11 8.6 ± 3.12 12.9 ± 4.52 21.9 ± 2.77 27 ± 5.33 49.3 ± 5.48 67.8 ± 4.81 0 0.3 ± 0.17 1.2 ± 0.85 4.3 ± 1.18 9.7 ± 1.7 17.6 ± 1.64 33.5 ± 3.72 57.1 ± 2.1 79.2 ± 2.74 0-d-1 Risk 0.091 ± 0.001 0.17 ± 0.003 0.235 ± 0.005 0.282 ± 0.004 0.305 ± 0.009 0.308 ± 0.006 0.283 ± 0.009 0.216 ± 0.008 0.196 ± 0.003 0.094 ± 0.001 0.178 ± 0.005 0.249 ± 0.007 0.313 ± 0.016 0.309 ± 0.018 0.298 ± 0.019 0.1 0.199 0.297 ± 0.002 0.386 ± 0.004 0.46 ± 0.005 0.516 ± 0.008 0.514 ± 0.021 0.46 ± 0.015 0.368 ± 0.016 Acc. on Unrejected 98.5 ± 1.52 98.1 ± 0.68 97.6 ± 0.38 98.1 ± 0.21 96.6 ± 0.39 94.1 ± 0.55 90.2 ± 0.52 84.6 ± 0.42 83.7 ± 0.7 100 98.8 ± 2.63 95.8 ± 1.62 93.1 ± 0.95 87.7 ± 0.94 81.2 ± 0.29 - - - - 95.9 ± 2.53 91.1 ± 2.4 84.8 ± 1.09 76.3 ± 1.33 71.2 ± 1.3 LS=0.5 Coverage 5.5 ± 0.97 10.7 ± 1.14 18.8 ± 2.41 30.9 ± 2.09 45.9 ± 1.53 61 ± 0.4 80.4 ± 0.82 98 ± 0.34 100 ± 0.04 0.6 ± 0.25 1.5 ± 0.47 7.9 ± 3.08 24.2 ± 1.22 50.2 ± 3.36 84.4 ± 3.5 0 0 0 0 1.9 ± 0.52 11.7 ± 3.74 36.1 ± 0.98 87.2 ± 1.55 99.8 ± 0.13 0-d-1 Risk 0.095 ± 0.001 0.181 ± 0.003 0.248 ± 0.007 0.283 ± 0.008 0.286 ± 0.007 0.27 ± 0.003 0.216 ± 0.006 0.167 ± 0.003 0.163 ± 0.007 0.099 0.197 ± 0.001 0.28 ± 0.008 0.32 ± 0.005 0.311 ± 0.01 0.252 ± 0.015 0.1 0.2 0.3 0.4 0.491 ± 0.002 0.54 ± 0.018 0.502 ± 0.007 0.309 ± 0.01 0.289 ± 0.013 Table 2: Performance results of NodeCwR-Cost with LS = 0 and LS = ϵ. Results with all values of cost(d) are mentioned in Table 4 4.7 COVERAGE AND ACCURACY COMPARISONS BETWEEN NODECWR-COST AND NODECWR-COV Here, we compare the performance of cost-based and coverage-based approaches. We do the com- parison using coverage vs. accuracy plots. Figure 3 shows the coverage versus accuracy plots for both cost-based and coverage-based approaches on different datasets. The cost-based approach (a) Cora (b) Pubmed (c) Citeseer Figure 3: Coverage and Accuracy comparison between NodeCwR-Cost and NodeCwR-Cov shows a clear advantage in terms of accuracy for most coverage rates. The reason is as follows. The coverage constraint in NodeCwR-Cov does not ensure the rejection of those examples that are hard to classify correctly. Thus, it may reject some of the easy examples. Thus, every coverage value may include more hard examples. Label smoothing makes this situation worse for NodeCwR-Cov due to soft labels. We also observe a very high standard deviation in the performance of NodeCwR- Cov. On the other hand, NodeCwR-Cost prefers to reject hard examples first by assigning a cost to rejection. This makes NodeCwR-Cost perform better than NodeCwR-Cov. 7 Under review as a conference paper at ICLR 2024 4.8 NODE EMBEDDING VISUALISATION We plotted t-SNE plots to represent the predicted class of each node. Coverage 50%-51.5% Coverage 69.3%-69.6% Coverage 81.3%-82.4% 0 = S L - , t s o C R w C e d o N 0 = S L , - v o C R w C e d o N ϵ = S L - , t s o C R w C e d o N ϵ = S L - , v o C R w C e d o N Figure 4: t-SNE plots representing predictions on Cora data set where black represents the reject option. It was noticeable that in both models, the rejected examples are usually the nodes that highly overlap between two or more classes. We can also notice that as the model coverage decreases, the number of examples it rejects increases and covers more overlapping boundaries between classes. It is worth noting that although the coverage and accuracy are almost similar in both models, the examples that each model chooses to reject are from different overlapping classes. 4.9 EXPERIMENTS WITH LABEL NOISE This section will discuss how label noise can affect the cost-based reject option classifiers learned for node classification. We consider symmetric label noise (10% and 20%). Figure 5 shows the effect of label noise on NodeCwR-Cost and NodeCwR-Cov in the absence of label smoothing. We vary the noise rate from 10% to 20%. We observe that the overall performance of both approaches worsens with the increase in the noise rate. Moreover, the coverage-based approach’s performance degrades more than the cost-based approach with label noise. 8 Under review as a conference paper at ICLR 2024 (a) Cora (b) Pubmed (c) Citeseer Figure 5: Effect of label noise on NodeCwR-Cost and NodeCwR-Cov in the LS = 0 setting. We performed experiments with label noise in the LS = ϵ setting to observe if label smoothing makes the learning robust. Figure 6 the results with label smoothing when there is label noise. We observe the following. In the cost-based models, when LS = ϵ, increasing the noise rate decreases the performance. However, compared to LS = 0, LS = ϵ models show better performance. Thus, label smoothing brings robustness against label noise in cost-based models. In the coverage-based models, when LS = ϵ, increasing the noise rate decreases the performance. However, label smooth- ing worsens the performance when there is label noise. Thus, label noise is ineffective in handling label noise in coverage-based models. NodeCwR-Cost (Coverage vs. Accuracy) NodeCwR-Cost d vs. 0 − d − 1 Risk NodeCwR-Cov (Coverage vs. Accuracy) a r o C d e m b u P r e e s e t i C Figure 6: Effect of label noise on NodeCwR-Cost and NodeCwR-Cov in LS = ϵ setting. The actual numbers can be seen in Tables 3, 4, 5, and 6 in Appendix A and B. 5 CONCLUSION We proposed a foundational model for node classification, which can abstain from making a predic- tion when uncertain. We set up abstention-based GAT architecture to learn node embeddings and show the effectiveness of two abstention models for graphs, which can be highly useful in high-risk applications. Our code implementation is added to the supplementary file. 9 Under review as a conference paper at ICLR 2024 REFERENCES Diego Antognini. pygat. https://github.com/Diego999/pyGAT, 2021. Peter L Bartlett and Marten H Wegkamp. Classification with a reject option using a hinge loss. JMLR, 9(Aug):1823–1840, 2008. Xavier Bresson and Thomas Laurent. Residual gated graph convnets. arXiv preprint arXiv:1711.07553, 2017. Yuzhou Cao, Tianchi Cai, Lei Feng, Lihong Gu, Jinjie GU, Bo An, Gang Niu, and Masashi Sugiyama. Generalizing consistent multi-class classification with rejection to be compatible with arbitrary losses. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh (eds.), Advances in Neural Information Processing Systems, volume 35, pp. 521–534. Curran Associates, Inc., 2022. Nontawat Charoenphakdee, Zhenghang Cui, Yivan Zhang, and Masashi Sugiyama. Classification with rejection based on cost-sensitive classification. In Marina Meila and Tong Zhang (eds.), Pro- ceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research, pp. 1507–1517. PMLR, 18–24 Jul 2021. Zhengdao Chen, Soledad Villar, Lei Chen, and Joan Bruna. On the equivalence between graph isomorphism testing and function approximation with gnns. Advances in neural information processing systems, 32, 2019. C Chow. On optimum recognition error and reject tradeoff. IEEE Transactions on information theory, 16(1):41–46, 1970. Djork-Arn´e Clevert, Thomas Unterthiner, and Sepp Hochreiter. Fast and accurate deep network learning by exponential linear units (elus). arXiv preprint arXiv:1511.07289, 2015. Corinna Cortes, Giulia DeSalvo, and Mehryar Mohri. Learning with rejection. In Proceedings of 27th Conference on Algorithmic Learning Theory (ALT), volume 9925, pp. 67–82, Bari, Italy, 2016. Micha¨el Defferrard, Xavier Bresson, and Pierre Vandergheynst. Convolutional neural networks on graphs with fast localized spectral filtering. Advances in neural information processing systems, 29, 2016. Qian Dong and Shuzi Niu. Legal judgment prediction via relational learning. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 983–992, 2021. Ran El-Yaniv et al. On the foundations of noise-free selective classification. JMLR, 11(5), 2010. Yonatan Geifman and Ran El-Yaniv. Selectivenet: A deep neural network with an integrated reject option. In International conference on machine learning, pp. 2151–2159. PMLR, 2019. Yves Grandvalet, Alain Rakotomamonjy, Joseph Keshet, and St´ephane Canu. Support vector ma- chines with a reject option. In NIPS, pp. 537–544, 2009. William L. Hamilton, Zhitao Ying, and Jure Leskovec. Inductive Representation Learning on Large Graphs. In NIPS, pp. 1024–1034, 2017. Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167, 2015. Bhavya Kalra, Kulin Shah, and Naresh Manwani. Risan: Robust instance specific deep abstention network. In Proceedings of the 37th Conference on Uncertainty in Artificial Intelligence, volume 161, pp. 1525–1534, 27–30 Jul 2021. Thomas N. Kipf and Max Welling. Semi-Supervised Classification with Graph Convolutional Net- works. In ICLR, 2017. 10 Under review as a conference paper at ICLR 2024 Michal Lukasik, Srinadh Bhojanapalli, Aditya Krishna Menon, and Sanjiv Kumar. Does label In Proceedings of the 37th International Conference on Ma- smoothing mitigate label noise? chine Learning, ICML’20, 2020. Naresh Manwani, Kalpit Desai, Sanand Sasidharan, and Ramasubramanian Sundararajan. Double ramp loss based reject option classifier. In PAKDD, pp. 151–163, 2015. Haggai Maron, Heli Ben-Hamu, Hadar Serviansky, and Yaron Lipman. Provably powerful graph networks. Advances in neural information processing systems, 32, 2019. Christopher Morris, Martin Ritzert, Matthias Fey, William L Hamilton, Jan Eric Lenssen, Gaurav Rattan, and Martin Grohe. Weisfeiler and leman go neural: Higher-order graph neural networks. In Proceedings of the AAAI conference on artificial intelligence, volume 33, pp. 4602–4609, 2019. Chenri Ni, Nontawat Charoenphakdee, Junya Honda, and Masashi Sugiyama. On the calibration of multiclass classification with rejection. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch´e- Buc, E. Fox, and R. Garnett (eds.), Advances in Neural Information Processing Systems, vol- ume 32. Curran Associates, Inc., 2019. Harish G Ramaswamy, Ambuj Tewari, Shivani Agarwal, et al. Consistent algorithms for multiclass classification with an abstain option. Electronic Journal of Statistics, 12(1):530–554, 2018. Victor Garcia Satorras and Joan Bruna Estrach. Few-shot learning with graph neural networks. In International conference on learning representations, 2018. Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini. The graph neural network model. IEEE transactions on neural networks, 20(1):61–80, 2008. M. Schlichtkrull, Thomas Kipf, Peter Bloem, Rianne van den Berg, Ivan Titov, and Max Welling. Modeling relational data with graph convolutional networks. In Extended Semantic Web Confer- ence, 2017. URL https://api.semanticscholar.org/CorpusID:5458500. Prithviraj Sen, Galileo Namata, Mustafa Bilgic, Lise Getoor, Brian Galligher, and Tina Eliassi- Rad. Collective classification in network data. AI Magazine, 29(3):93, Sep. 2008. doi: 10.1609/aimag.v29i3.2157. URL https://ojs.aaai.org/aimagazine/index.php/ aimagazine/article/view/2157. Kulin Shah and Naresh Manwani. Sparse reject option classifier using successive linear program- ming. In AAAI, volume 33, pp. 4870–4877, 2019. Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: a simple way to prevent neural networks from overfitting. The journal of machine learning research, 15(1):1929–1958, 2014. Zhenchao Sun, Hongzhi Yin, Hongxu Chen, Tong Chen, Lizhen Cui, and Fan Yang. Disease pre- diction via graph neural networks. IEEE Journal of Biomedical and Health Informatics, 25(3): 818–826, 2021. doi: 10.1109/JBHI.2020.3004143. C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna. Rethinking the inception architecture In 2016 IEEE Conference on Computer Vision and Pattern Recognition for computer vision. (CVPR), pp. 2818–2826, Los Alamitos, CA, USA, jun 2016. IEEE Computer Society. doi: 10. 1109/CVPR.2016.308. Petar Veliˇckovi´c, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Li`o, and Yoshua Bengio. Graph Attention Networks. In ICLR, 2018. Jiaheng Wei, Hangyu Liu, Tongliang Liu, Gang Niu, and Yang Liu. To smooth or not? when label smoothing meets noisy labels. In International Conference on Machine Learning, 2021. URL https://api.semanticscholar.org/CorpusID:246485845. Tian Xia and Wei-Shinn Ku. Geometric graph representation learning on protein structure predic- tion. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining, pp. 1873–1883, 2021. 11 Under review as a conference paper at ICLR 2024 Bingbing Xu, Huawei Shen, Bingjie Sun, Rong An, Qi Cao, and Xueqi Cheng. Towards consumer loan fraud detection: Graph neural networks with role-constrained conditional random field. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pp. 4537–4545, 2021. Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How powerful are graph neural networks? In International Conference on Learning Representations, 2018. 12 Under review as a conference paper at ICLR 2024 A EXPERIMENTAL RESULTS OF NCWR-COV ON NOISY LABELS WITH LABEL SMOOTHING Dataset Coverage Noise=0.1, LS=0 Noise=0.1, LS=0.5 Noise=0.2, LS=0 Noise=0.2, LS=0.5 Cora Pubmed Citeseer 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 96.63 ± 2.387 95.44 ± 1.841 93.96 ± 2.229 92.28 ± 2.627 90.65 ± 2.463 88.52 ± 2.837 86.36 ± 2.344 84.12 ± 2.167 81.89 ± 2.071 88 ± 8.92 74.9 ± 12.03 84.1 ± 3.88 82.3 ± 3.97 79.8 ± 1.82 77.6 ± 2.1 78.5 ± 1.88 75.8 ± 3.37 74 ± 1.83 79.8 ± 8.14 74.9 ± 14.26 83.9 ± 3.86 79.6 ± 2.36 76 ± 2.35 70.7 ± 2.4 70.4 ± 2.86 68.8 ± 3.07 68.5 ± 3.47 94.75 ± 3.196 93.56 ± 2.597 91.96 ± 2.312 90.94 ± 1.898 89.9 ± 1.317 87.9 ± 1.095 86.41 ± 1.354 84.25 ± 1.501 81.9 ± 2.059 84.6 ± 4.93 80.8 ± 15.09 80.3 ± 7.07 77.5 ± 4.55 79.9 ± 2.84 76.8 ± 3.62 78.6 ± 2.87 74.9 ± 2.06 73.6 ± 1.71 86 ± 6.65 83.3 ± 2.97 83 ± 4.15 76.9 ± 5.33 71.9 ± 7.83 74.6 ± 2.01 70.3 ± 4.42 69.2 ± 4.08 68.1 ± 2.6 92.75 ± 2.55 91.44 ± 3.51 89.87 ± 3.06 88.59 ± 3.362 86.17 ± 3.152 83.43 ± 3.604 80.54 ± 3.232 78.15 ± 3.247 75.22 ± 2.906 81.4 ± 7.67 82.8 ± 9.83 81.1 ± 2.9 74.4 ± 5.5 66.8 ± 4.22 75.4 ± 5.63 69.7 ± 3.43 70.8 ± 3.76 70.6 ± 1.39 69.8 ± 24.56 77.2 ± 4.47 68.1 ± 5.17 76.3 ± 2.63 67.7 ± 5.51 70.9 ± 3.77 66.4 ± 4.13 65.3 ± 3.12 64.1 ± 3.09 93.12 ± 1.959 90.88 ± 3.091 88.66 ± 3.436 86.97 ± 3.687 85.38 ± 3.777 83.75 ± 3.411 81.01 ± 3.299 78.2 ± 2.909 74.9 ± 2.943 81.2 ± 5.76 70.3 ± 8.93 77.2 ± 3.95 74.5 ± 2.89 74.8 ± 4.71 71.5 ± 5.55 70.7 ± 4.86 70.1 ± 3.9 70.5 ± 4.27 75.5 ± 7.11 76.8 ± 5.83 70.7 ± 6.68 71.4 ± 4.71 68.1 ± 4.39 68.3 ± 3.78 63.2 ± 8.25 67 ± 2.3 66.9 ± 4.89 Table 3: Accuracy and Coverage of NCwR-Cov on noisy labels with Label Smoothing. 13 Under review as a conference paper at ICLR 2024 B EXPERIMENTAL RESULTS OF NCWR-COST WITH LABEL SMOOTHING a r o C d e m b u P r e e s e t i C d 95 ± 0.49 Acc. on Unrejected 97.5 ± 0.48 0.1 0.15 97.3 ± 0.42 97.5 ± 0.47 0.2 0.25 97.2 ± 0.79 97.5 ± 0.68 0.3 0.35 97.2 ± 0.18 96.6 ± 0.62 0.4 0.45 96.2 ± 0.37 95.8 ± 0.23 0.5 0.55 95.4 ± 0.18 0.6 0.65 94.2 ± 0.21 92.8 ± 0.55 0.7 0.75 91.5 ± 0.39 90.1 ± 0.51 0.8 0.85 87.2 ± 0.78 82.4 ± 0.42 1 97.4 ± 1.86 0.1 0.15 98.6 ± 1.4 97.7 ± 2.49 0.2 0.25 95.5 ± 1.21 93.5 ± 1.2 0.3 0.35 93.2 ± 1.8 92.4 ± 0.66 0.4 0.45 90 ± 1.08 88.9 ± 0.92 0.5 0.55 87.3 ± 1.77 84.6 ± 0.87 0.6 0.65 83.5 ± 0.36 77.1 ± 0.29 1 0.1 - 0.15 100 0.2 100 0.25 98.9 ± 2.49 99.2 ± 1.72 0.3 0.35 95.3 ± 2.91 93.7 ± 2.26 0.4 0.45 93.6 ± 3.76 91.6 ± 2.23 0.5 0.55 90.9 ± 1.33 87.9 ± 0.88 0.6 0.65 86.7 ± 0.7 85.5 ± 0.95 0.7 0.75 83.2 ± 0.96 79.5 ± 0.72 0.8 0.83 75.8 ± 1.61 70.3 ± 0.5 1 LS=0 Coverage 12.1 ± 0.95 15.2 ± 1.29 17.1 ± 1.6 21.5 ± 2.31 23.8 ± 1.75 27.8 ± 1.73 32.2 ± 0.91 37.2 ± 2.36 42.6 ± 1.88 47.5 ± 1.12 53.1 ± 1.07 59.4 ± 1.87 66.3 ± 1.81 74.3 ± 0.87 83.3 ± 0.68 90.5 ± 1.11 100 8.6 ± 3.12 8.3 ± 2.79 12.9 ± 4.52 15.9 ± 2.07 21.9 ± 2.77 23.9 ± 4.89 27 ± 5.33 37.8 ± 2.91 49.3 ± 5.48 55.9 ± 6.91 67.8 ± 4.81 73.2 ± 1.67 100 0 0.6 ± 0.42 0.3 ± 0.17 0.8 ± 0.67 1.2 ± 0.85 3.3 ± 0.79 4.3 ± 1.18 6.9 ± 1.74 9.7 ± 1.7 14 ± 1.28 17.6 ± 1.64 24.7 ± 1.58 33.5 ± 3.72 43.6 ± 2.13 57.1 ± 2.1 79.2 ± 2.74 100 Noise rate=0 0-d-1 Risk 0.091 ± 0.001 0.131 ± 0.002 0.17 ± 0.003 0.203 ± 0.004 0.235 ± 0.005 0.26 ± 0.005 0.282 ± 0.004 0.297 ± 0.01 0.305 ± 0.009 0.311 ± 0.005 0.308 ± 0.006 0.298 ± 0.01 0.283 ± 0.009 0.256 ± 0.005 0.216 ± 0.008 0.196 ± 0.003 0.176 ± 0.004 0.094 ± 0.001 0.139 ± 0.003 0.178 ± 0.005 0.218 ± 0.003 0.249 ± 0.007 0.283 ± 0.011 0.313 ± 0.016 0.318 ± 0.007 0.309 ± 0.018 0.314 ± 0.02 0.298 ± 0.019 0.295 ± 0.008 0.229 ± 0.003 0.1 0.149 ± 0.001 0.199 0.248 ± 0.001 0.297 ± 0.002 0.34 ± 0.002 0.386 ± 0.004 0.424 ± 0.005 0.46 ± 0.005 0.486 ± 0.007 0.516 ± 0.008 0.523 ± 0.007 0.514 ± 0.021 0.496 ± 0.011 0.46 ± 0.015 0.368 ± 0.016 0.297 ± 0.005 Acc. on Unrejected 98.5 ± 1.52 97 ± 1.03 98.1 ± 0.68 97.7 ± 0.38 97.6 ± 0.38 98 ± 0.12 98.1 ± 0.21 97.6 ± 0.59 96.6 ± 0.39 95.2 ± 0.51 94.1 ± 0.55 92.2 ± 0.73 90.2 ± 0.52 86.8 ± 0.61 84.6 ± 0.42 83.7 ± 0.7 82.2 ± 0.4 100 100 98.8 ± 2.63 96.1 ± 3.05 95.8 ± 1.62 94.7 ± 2.69 93.1 ± 0.95 90.7 ± 1.03 87.7 ± 0.94 84.6 ± 0.67 81.2 ± 0.29 78 ± 1.14 77.2 ± 0.94 - - - - - - - 97.5 ± 5.59 95.9 ± 2.53 97.1 ± 1.77 91.1 ± 2.4 87.3 ± 1.32 84.8 ± 1.09 81.6 ± 1.58 76.3 ± 1.33 71.2 ± 1.3 70.8 ± 0.44 LS=0.5 Coverage 5.5 ± 0.97 6.8 ± 0.74 10.7 ± 1.14 15 ± 0.68 18.8 ± 2.41 26.3 ± 2.42 30.9 ± 2.09 38.2 ± 2.01 45.9 ± 1.53 54.6 ± 1.74 61 ± 0.4 70.6 ± 1.49 80.4 ± 0.82 91.1 ± 1.05 98 ± 0.34 100 ± 0.04 100 0.6 ± 0.25 1 ± 0.79 1.5 ± 0.47 4.8 ± 0.9 7.9 ± 3.08 13.5 ± 3.03 24.2 ± 1.22 35.6 ± 1.91 50.2 ± 3.36 66.1 ± 4.13 84.4 ± 3.5 95.9 ± 0.47 100 0 0 0 0 0 0 0 0.6 ± 0.25 1.9 ± 0.52 4.8 ± 0.49 11.7 ± 3.74 22.4 ± 1.68 36.1 ± 0.98 59 ± 2.21 87.2 ± 1.55 99.8 ± 0.13 100 0-d-1 Risk 0.095 ± 0.001 0.142 ± 0.001 0.181 ± 0.003 0.216 ± 0.002 0.248 ± 0.007 0.263 ± 0.008 0.283 ± 0.008 0.287 ± 0.007 0.286 ± 0.007 0.276 ± 0.007 0.27 ± 0.003 0.246 ± 0.005 0.216 ± 0.006 0.187 ± 0.008 0.167 ± 0.003 0.163 ± 0.007 0.178 ± 0.004 0.099 0.148 ± 0.001 0.197 ± 0.001 0.24 ± 0.003 0.28 ± 0.008 0.31 ± 0.008 0.32 ± 0.005 0.323 ± 0.008 0.311 ± 0.01 0.288 ± 0.017 0.252 ± 0.015 0.238 ± 0.01 0.228 ± 0.009 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.448 ± 0.001 0.491 ± 0.002 0.525 ± 0.003 0.54 ± 0.018 0.533 ± 0.01 0.502 ± 0.007 0.416 ± 0.02 0.309 ± 0.01 0.289 ± 0.013 0.292± 0.004 Table 4: Performance results of NodeCwR-Cost with LS = 0 and LS = ϵ. 14 Under review as a conference paper at ICLR 2024 a r o C d e m b u P r e e s e t i C d Acc. on Unrejected 95.8 ± 1.27 0.1 0.15 96.6 ± 1.45 94.9 ± 1.96 0.2 0.25 96.1 ± 1.09 95.6 ± 0.68 0.3 0.35 96.7 ± 1.33 96.1 ± 0.88 0.4 0.45 95.2 ± 0.82 94.9 ± 1.2 0.5 0.55 93.6 ± 0.84 93.1 ± 1.91 0.6 0.65 93.1 ± 1.78 91.4 ± 1.11 0.7 0.75 88 ± 1.04 88 ± 1.46 0.8 0.85 83.8 ± 1.78 77.3 ± 0.98 1 96 ± 3.33 0.1 0.15 91.2 ± 3.14 91.2 ± 0.77 0.2 0.25 93.4 ± 2.82 91.9 ± 2.11 0.3 0.35 88.9 ± 2.75 86.4 ± 2.28 0.4 0.45 84.7 ± 2.78 85.6 ± 2.43 0.5 0.55 82 ± 2.29 80.4 ± 1.48 0.6 0.65 77.1 ± 3.33 70.3 ± 1.18 1 0.1 - 0.15 - 96.4± 8.13 0.2 0.25 93.6 ±6.3 93.5 ±6.15 0.3 0.35 91.5± 5.61 87 ± 6.59 0.4 0.45 86.1± 7.48 87.7± 2.65 0.5 0.55 86.7 ±6.75 83.3 ±5.14 0.6 0.65 85.1± 1.91 80.7± 1.96 0.7 0.75 77.4± 1.94 76.2± 2.11 0.8 0.83 72.8 ±1.27 66.8 ±2.35 1 LS=0 Coverage 9.2 ± 1.6 10.9 ± 0.72 13.5 ± 1.85 17.1 ± 1.32 20.3 ± 1.63 20.4 ± 1.91 25.7 ± 2.11 31 ± 1.78 37.3 ± 4.04 39.7 ± 3.91 49 ± 3.61 53.6 ± 1.72 61.9 ± 4.48 71.6 ± 3.93 80.8 ±1.62 91.2 ±0.83 100 4 ± 1.74 7.5 ± 2.37 8.2 ± 1.65 12 ± 4.25 15.5 ± 3.95 18.9 ± 9.44 30 ± 4.1 34.3 ± 2.33 42.5 ± 4.29 53.2 ± 5.56 58.5 ± 4.24 72.6 ± 7.61 100 - - 0.6 ± 0.37 0.8 ± 0.34 0.9 ± 0.54 2.1 ± 1.03 2.9 ± 1 4.4 ± 0.43 8.3 ± 2.26 11.4 ±3.82 16.5 ±0.95 22.4 ±2.87 29.2 ±2.54 39.6± 2.14 56.3 ±3.56 78.8 ±5.09 100 ± Noise rate=0.1 0-d-1 Risk 0.095 ± 0.001 0.137 ± 0.002 0.18 ± 0.003 0.214 ± 0.002 0.248 ± 0.005 0.285 ± 0.007 0.307 ± 0.008 0.326 ± 0.005 0.333 ± 0.02 0.357 ± 0.021 0.34 ± 0.022 0.339 ± 0.01 0.32 ± 0.023 0.299 ± 0.03 0.25 ± 0.015 0.223 0± 0.011 0.227 ± 0.01 0.098 ± 0.001 0.146 ± 0.002 0.191 ± 0.002 0.228 ± 0.008 0.267 ± 0.007 0.306 ± 0.018 0.321 ± 0.011 0.349 ± 0.009 0.349 ± 0.017 0.354 ± 0.017 0.363 ± 0.025 0.346 ± 0.023 0.297 ± 0.012 - - 0.199 ±0.001 0.248 ±0.001 0.298± 0.001 0.345 ±0.003 0.393± 0.001 0.436± 0.004 0.469± 0.007 0.501 ±0.02 0.528± 0.011 0.538 ±0.017 0.551± 0.017 0.542 ±0.014 0.484± 0.027 0.395 ±0.038 0.332± 0.0235 Acc. on Unrejected 97.6 ± 2.16 98.2 ± 1.07 97.8 ± 0.9 97 ± 1.46 96.9 ± 0.53 97.4 ± 0.66 97.1 ± 0.62 96.4 ± 0.95 96.7 ± 0.53 95 ± 0.85 94 ± 0.63 91.8 ± 1.2 88.9 ± 1.11 85 ± 1.4 81.7 ± 2.35 80.1 ± 2.21 77.5 ± 5.74 100 89.6 ± 12.2 93.7 ± 7.95 93.5 ± 2.38 94 ± 2.57 91.2 ± 2.46 90.7 ± 1.7 84 ± 4.36 85.1 ± 2.21 82.6 ± 2.3 76.3 ± 2.32 74.2 ± 3.67 73.2 ± 3.19 - - - - - - - 93.3± 14.9 88.8± 87.9 ±3.13 88.3 ±1.56 87.1 ±0.93 82.7± 3.4 82.1 ±2.28 73.1± 2.55 68.6± 2.39 67.4 ±2.25 LS=0.5 Coverage 3.4 ± 1.02 4.6 ± 1.04 8.1 ± 1.04 9.7 ± 2.22 14.1 ± 1.29 19.6 ± 2.19 24.2 ± 4 29.4 ± 2.55 38.3 ± 2.69 48 ± 4.89 55.1 ± 2.34 66.9 ± 2.01 77.9 ± 1.99 88.3 ± 1.47 98.2 ± 0.82 100 100 0.4 ± 0.26 1 ± 0.6 2.1 ± 1.05 5.3 ± 1.32 7.1 ± 1.99 11.7 ± 1.97 19.5 ± 5.34 28.6 ± 2.89 46.2 ± 4.52 62.2 ± 5.59 81.5 ± 4.47 94.3 ± 2.38 100 - - - - - - - 0.8 ± 0.73 5.2 ± 1.4 0.66 3.8 ± 1.26 9.4 ± 1.18 19.3 ±2.72 31.1± 4.08 55.1 ±4.71 85.1± 2.74 99.8± 0.25 100± 0-d-1 Risk 0.097 ± 0.001 0.144 ± 0.001 0.186 ± 0.002 0.229 ± 0.005 0.262 ± 0.003 0.286 ± 0.007 0.31 ± 0.014 0.328 ± 0.01 0.321 ± 0.014 0.31 ± 0.025 0.302 ± 0.012 0.27 ± 0.015 0.241 ± 0.014 0.22 ± 0.016 0.194 ± 0.02 0.199 ± 0.022 0.225 ± 0.058 0.1 0.15 ± 0.001 0.198 ± 0.002 0.24 ± 0.003 0.283 ± 0.003 0.319 ± 0.007 0.34 ± 0.017 0.368 ± 0.01 0.339 ± 0.009 0.316 ± 0.03 0.303 ± 0.032 0.279 ± 0.04 0.268 ± 0.032 - - - - - - - 0.447 ±0.004 0.494± 0.003 0.533 ±0.006 0.554 ±0.006 0.549± 0.014 0.536± 0.021 0.435± 0.034 0.349± 0.016 0.315± 0.024 0.326 ±0.023 Table 5: Performance results of NodeCwR-Cost with LS = 0 and LS = ϵ on noise 0.1 15 Under review as a conference paper at ICLR 2024 a r o C d e m b u P r e e s e t i C d Acc. on Unrejected 95.2 ±1.68 0.1 0.15 93.5 ±2.19 94.3 ±1.64 0.2 0.25 95.1 ±3.1 94.8 ±0.95 0.3 0.35 93.3 ±1.71 93.9 ±1.24 0.4 0.45 92.4 ±1.66 94.1 ±0.56 0.5 0.55 90.8 ±2.26 89.8 ±1.74 0.6 0.65 89.4 ±2.5 88.6 ±2.48 0.7 0.75 87.2 ±2.45 82.3 ±2.59 0.8 0.85 80.3 ±2.94 71.9 ±2.36 1 84.8 ±8.27 0.1 0.15 87.3 ±3.05 85.2 ±4.61 0.2 0.25 87.2 ±2.19 90.2 ±5.48 0.3 0.35 84.7 ±2.68 84.8 ±4.75 0.4 0.45 78.8 ±6.32 0.5 0.55 79.2 ±4.55 75.5 ±3.39 0.6 0.65 73.3 ±6.09 64.1 ±4.95 1 0.1 - 0.15 - 0.2 100 0.25 100 91 ±14.51 0.3 0.35 89.6 ±8.95 82.5 ±5.38 0.4 0.45 79 ±10.23 75.9± 2.53 0.5 0.55 81.3 ±2.11 0.6 0.65 80.8 ±2.35 0.7 0.75 75.9 ±2.03 71.2 ±3.87 0.8 0.83 67.3 ±6.49 1 80 ±3.25 59 ±4.09 77 ±4.45 77 ±7.54 LS=0 Coverage 6.7 ±2.05 7.3 ±0.69 9.8 ±1.42 14 ±1.53 14.5 ±2.76 16.7 ±1.21 22.6 ±2.3 25.9 ±2.69 30.1 ±3.19 35.3 ±4.13 41.9 ±3.4 48.6 ±4.73 60.7 ±4.5 67.2 ±4.52 79 ±1.6 90.6 ±2.04 100 3.5 ±1.07 6.7 ±3.39 8.5 ±3.41 9.8 ±3.32 12.8 ±2.83 17 ±3.63 20.8 ±5.36 28.1 ±5.13 34.4 ±8.37 44.3 ±6.56 59.5 ±5.98 65.5 ±2.91 100 ±0 - - 0.4 ±0.2 0.5 ±0.15 0.9 ±0.6 1.9 ±0.95 3.5 ±1.21 4 ±1.01 5.6 ±1 9.8 ±2.63 13.2 ±4.36 21.2 ±3.53 24.9 ±2.95 35 ±6.5 52.5 ±2.85 77.8 ±3.85 100 Noise rate=0.2 0-d-1 Risk 0.096 ±0.002 0.144 ±0.001 0.186 ±0.002 0.222 ±0.005 0.264 ±0.007 0.303 ±0.004 0.323 ±0.010 0.353 ±0.010 0.367 ±0.015 0.388 ±0.023 0.391 ±0.017 0.386 ±0.029 0.345 ±0.012 0.333 ±0.017 0.308 ±0.027 0.259 ±0.023 0.281 ±0.023 0.101 ±0.002 0.149 ±0.002 0.196 ±0.004 0.238 ±0.006 0.275 ±0.005 0.317 ±0.008 0.349 ±0.013 0.384 ±0.02 0.396 ±0.032 0.399 ±0.029 0.389 ±0.029 0.399 ±0.042 0.359 ±0.05 - - 0.199 ±0.001 0.249 ±0.001 0.299 ±0.001 0.345 ±0.003 0.392 ±0.004 0.44 ±0.006 0.485 ±0.003 0.514 ±0.01 0.549 ±0.026 0.553 ±0.019 0.582 ±0.022 0.572 ±0.033 0.532 ±0.014 0.445 ±0.035 0.41 ±0.041 Acc. on Unrejected 96.6 ±4.08 96.7 ±3.15 94.5 ±4.61 95.5 ±3.67 96.5 ±1.68 96.4 ±1.09 96.1 ±1 97.1 ±0.89 95.1 ±1.13 95 ±1.29 92.1 ±0.93 90.3 ±1.93 87.7 ±1.16 82.1 ±1.97 79.1 ±1.59 77 ±3.17 73.6 ±3.1 92.2 ±14.4 94.5 ±12.2 92.2 ±7.54 84.2 ±11.8 90.2 ±4.54 89.9 ±3.37 80.4 ±8.24 83.8 ±4.15 80.7 ±1.49 76.2 ±7.03 72.5 ±2.77 71.1 ±3.93 65.5 ±3.74 - - - - - - - 91.2 ±11.8 86.2 ±15.2 88.2 ±6.01 77.6 ±6.38 80.3 ±2.37 81.9 ±2.72 69.3 ±9 69.1 ±5.66 64.7 ±3.79 63.7 ±5.07 LS=0.5 Coverage 2.3 ±0.87 2.5 ±0.58 4.2 ±1.6 7.1 ±1.26 9.7 ±2.02 14.2 ±3.35 18.6 ±1.9 25.5 ±2.8 28.8 ±5.19 39.2 ±3.37 50.8 ±3.72 61.4 ±2.34 73.8 ±3.51 87.8 ±3.31 97.4 ±0.33 100 ±0.04 100 0.7 ±0.64 0.9 ±0.76 1.5 ±0.65 3.5 ±3.51 5.8 ±0.94 11.1 ±2.87 16.3 ±3.08 23.2 ±5.02 39.7 ±3.03 58.3 ±4.75 68.6 ±10.42 90 ±5 100 0 - - - - - - - 0.4 ±0.4 1.7 ±1.6 4.6 ±2.5 8.2 ±0.86 12.4 ±4.05 27.3 ±5.84 49.1 ±5.48 81.4 ±3.46 99.9 ±0.19 100 0-d-1 Risk 0.098 ±0.001 0.147 ±0.001 0.193 ±0.004 0.235 ±0.004 0.274 ±0.007 0.305 ±0.012 0.333 ±0.007 0.343 ±0.01 0.37 ±0.03 0.354 ±0.015 0.336 ±0.012 0.31 ±0.02 0.274 ±0.019 0.249 ±0.012 0.224 ±0.015 0.231 ±0.032 0.264 ±0.031 0.1 ±0.001 0.149 ±0.002 0.198 ±0.001 0.248 ±0.003 0.288 ±0.004 0.323 ±0.007 0.367 ±0.015 0.384 ±0.016 0.378 ±0.009 0.369 ±0.039 0.377 ±0.04 0.326 ±0.034 0.345 ±0.037 - - - - - - - 0.449 ±0.001 0.493 ±0.007 0.531 ±0.008 0.569 ±0.007 0.593 ±0.019 0.557 ±0.038 0.532 ±0.05 0.402 ±0.034 0.353 ±0.038 0.373 ±0.0507 Table 6: Performance results of NodeCwR-Cost with LS = 0 and LS = ϵ and noise 0.2 16
