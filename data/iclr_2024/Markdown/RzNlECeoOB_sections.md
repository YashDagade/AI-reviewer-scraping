## Abstract

The variational autoencoder (VAE) typically employs a standard normal prior as a regularizer for the probabilistic latent encoder. However, the Gaussian tail often decays too quickly to effectively accommodate the encoded points, failing to preserve crucial structures hidden in the data. In this paper, we explore the use of heavy-tailed models to combat over-regularization. Drawing upon insights from information geometry, we propose t3VAE, a modiﬁed VAE framework that incorporates Student’s t-distributions for the prior, encoder, and decoder. This results in a joint model distribution of a power form which we argue can better ﬁt real-world datasets. We derive a new objective by reformulating the evidence lower bound as joint optimization of KL divergence between two statistical manifolds and replacing with γ-power divergence, a natural alternative for power families. t3VAE demonstrates superior generation of low-density regions when trained on heavy- tailed synthetic data. Furthermore, we show that t3VAE signiﬁcantly outperforms other models on CelebA and imbalanced CIFAR-100 datasets. 1

## Introduction

The variational autoencoder (VAE, Kingma & Welling, 2013) is a popular probabilistic generative model for learning compact latent data representations. The VAE consists of two conditional models: an encoder which models the posterior distribution of the latent variable z given an observation x, and a decoder which infers the observation from its latent representation, which are jointly trained by optimizing the evidence lower bound (ELBO). The VAE framework a priori does not require the prior, encoder or decoder to be a particular probability distribution; the usual choice of Gaussian is mainly due to feasibility of the reparametrization trick and closed-form computation of divergence. However, real-world data frequently exhibits outlier-heavy or heavy-tailed behavior which is better captured by models of similar nature. Recently, Floto et al. (2023) showed that the Gaussian VAE encodes many points in low-density regions of the prior; the distribution is too tight to effectively ﬁt complex latent representations. We argue that distributing more mass to the tails allows encoded points to spread out easily, leading us to adopt a Student’s t-distributed prior. We also incorporate a t-distributed decoder which ampliﬁes variability of data generated from low-density regions. From a Bayesian perspective, this is equivalent to incorporating a latent precision affecting both x, z. Together with the prior, this results in a joint model pθ,ν(x, z) of a power form, generalizing the exponential form of the original VAE analogously to how the t-distribution generalizes the Gaussian. Changing the distributions usually necessitates numerical integration to estimate the ELBO. We provide a novel alternative based on recent theoretical insights from information geometry. Han et al. (2020) showed that the ELBO can be reformulated as minimization of KL divergence between two statistical manifolds. Separately, Eguchi (2021) has developed a theory of γ-power divergence that parallels KL divergence. In this new geometry, power families play the role of exponential families, *Equal contribution. 1 Published as a conference paper at ICLR 2024 providing a natural setting for joint optimization of heavy-tailed models. By minimizing γ-power instead of KL divergence, we construct a general-purpose framework implementing t-distributions for the prior, encoder and decoder and a new objective called γ-loss, which we call the t3VAE. t3VAE requires a single hyperparameter ν which is coupled to the degrees of freedom of the t- distributions and controls as a balance between reconstruction and regularization. In particular, t3VAE encompasses the Gaussian VAE and ordinary autoencoder as the limiting cases ν → ∞ and ν → 2, respectively. The γ-loss has an approximate closed form analogous to the ELBO and can be optimized via a t-reparametrization trick. We empirically demonstrate that t3VAE can successfully approximate low-density regions of heavy-tailed datasets. Furthermore, t3VAE is able to learn and generate high-dimensional images in richer detail compared to various alternative VAEs. Finally, we extend our model to a hierarchical architecture, the t3HVAE, which is able to reconstruct high-resolution images with more sophistication. 1.1
