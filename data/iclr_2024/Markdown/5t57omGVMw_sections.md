## Abstract

Solving a linear system Ax = b is a fundamental scientific computing primitive for which numerous solvers and preconditioners have been developed. These come with parameters whose optimal values depend on the system being solved and are often impossible or too expensive to identify; thus in practice sub-optimal heuristics are used. We consider the common setting in which many related linear systems need to be solved, e.g. during a single numerical simulation. In this scenario, can we sequentially choose parameters that attain a near-optimal overall number of iterations, without extra matrix computations? We answer in the affirmative for Successive Over-Relaxation (SOR), a standard solver whose parameter ω has a strong impact on its runtime. For this method, we prove that a bandit online learning algorithm—using only the number of iterations as feedback—can select parameters for a sequence of instances such that the overall cost approaches that of the best fixed ω as the sequence length increases. Furthermore, when given additional structural information, we show that a contextual bandit method asymptotically achieves the performance of the instance-optimal policy, which selects the best ω for each instance. Our work provides the first learning-theoretic treatment of high-precision linear system solvers and the first end-to-end guarantees for data-driven scientific computing, demonstrating theoretically the potential to speed up numerical

## Introduction

The bottleneck subroutine in many scientific computations is a solver returning an approximate so- lution to a linear system. For example, simulating a partial differential equation (PDE) often involves solving sequences of high-dimensional systems to very high precision (Thomas, 1999). A vast array of solvers and preconditioners have thus been developed, many of which have tunable parameters that significantly affect runtime (Greenbaum, 1997; Hackbusch, 2016). There is a long literature analyzing these algorithms, and indeed for some problems we have a strong understanding of the optimal parame- ters for a given matrix. However, computing them can be more costly than solving the original system, leading to an assortment of heuristics for setting good parameters (Ehrlich, 1981; Golub & Ye, 1999). We provide an alternative to such heuristics by taking advantage of the fact that we often sequentially solve many linear systems. In addition to numerical simulation, this occurs in graphics computations such as mean-curvature flow (Kazhdan et al., 2012), nonlinear system solvers (Marquardt, 1963), and beyond. A natural approach is to treat these instances as data to be passed to a machine learning (ML) algorithm; in particular the framework of online learning (Cesa-Bianchi & Lugosi, 2006) provides a language to reason about such sequential learning problems. For example, if we otherwise would solve a sequence of linear systems (A1, b1), . . . , (AT , bT ) using a given solver with a fixed parameter, can we use ML to do as well as the best choice of that parameter, i.e. can we minimize regret? Or, if the matrices are all diagonal shifts of single matrix A, can we learn the functional relationship between the shift ct and the optimal solver parameter for At = A + ctIn, i.e. can we predict using context? We investigate these questions for the Successive Over-Relaxation (SOR) solver, a generalization of Gauss-Seidel whose relaxation parameter ω ∈ (0, 2) dramatically affects the number of iterations (c.f. Figure 1, noting the log-scale). SOR and its symmetric variant are well-studied and often used as pre- conditioners for Krylov
