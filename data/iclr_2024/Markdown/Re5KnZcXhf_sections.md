## Abstract

Out-of-distribution (OOD) generalization aims at dealing with scenarios where the test data distribution can largely differ from training data distributions. Existing works for OOD generalization on graphs generally propose to extract invariant subgraphs that provide crucial classification information even under unseen test distributions. However, such a strategy is suboptimal due to two challenges: (1) intra-graph correlations, i.e., correlated structures that are partial invariant, and (2) inter-graph distinctions, i.e., significant distribution shifts among graphs. To solve these challenges and achieve better generalizability, we innovatively propose a Constrained Variational Generation (CVG) framework to generate generalizable graphs for classification. Our framework is implemented based on the Variation Graph Auto-Encoder (VGAE) structure and optimized under the guidance of the Graph Information Bottleneck (GIB) principle, with its effectiveness validated by our theoretical analysis. We conduct extensive experiments on real-world datasets and demonstrate the superiority of our framework over state-of-the-art baselines. 1

## Introduction

Graph-structured data is present in various crucial real-world domains, such as social networks, biological networks, and chemical molecules (Xu et al., 2019). Recently, relevant works have fo- cused on learning graph representations by encoding graphs into vectorized representations (Wu et al., 2019). Graph Neural Networks (GNNs) (Kipf & Welling, 2017; Veliˇckovi´c et al., 2018), for instance, employ an iterative learning mechanism to extract valuable graph information and have achieved success in various real-world applications. However, current
