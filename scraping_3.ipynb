{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-27 01:24:38,053 - INFO - ====== WebDriver manager ======\n",
      "2024-10-27 01:24:38,179 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-10-27 01:24:38,510 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-10-27 01:24:38,665 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-10-27 01:24:38,920 - INFO - WebDriver version 130.0.6723.69 selected\n",
      "2024-10-27 01:24:38,922 - INFO - Modern chrome version https://storage.googleapis.com/chrome-for-testing-public/130.0.6723.69/mac-arm64/chromedriver-mac-arm64.zip\n",
      "2024-10-27 01:24:38,922 - INFO - About to download new driver from https://storage.googleapis.com/chrome-for-testing-public/130.0.6723.69/mac-arm64/chromedriver-mac-arm64.zip\n",
      "2024-10-27 01:24:39,009 - INFO - Driver downloading response is 200\n",
      "2024-10-27 01:24:39,485 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-10-27 01:24:39,644 - INFO - Driver has been saved in cache [/Users/yd211/.wdm/drivers/chromedriver/mac64/130.0.6723.69]\n",
      "2024-10-27 01:24:44,435 - INFO - ====== WebDriver manager ======\n",
      "2024-10-27 01:24:44,510 - INFO - Get LATEST chromedriver version for google-chrome\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://openreview.net/forum?id=AOSsLRKQrX\n",
      "https://openreview.net/forum?id=fMX07g3prp\n",
      "https://openreview.net/forum?id=KS8mIvetg2\n",
      "https://openreview.net/forum?id=Re5KnZcXhf\n",
      "https://openreview.net/forum?id=JzvIWvC9MG\n",
      "https://openreview.net/forum?id=WpMHBIYsUf\n",
      "https://openreview.net/forum?id=My7lkRNnL9\n",
      "https://openreview.net/forum?id=dER6OpDTnq\n",
      "https://openreview.net/forum?id=F2MdnvZl3D\n",
      "https://openreview.net/forum?id=mnyXZBa5dP\n",
      "https://openreview.net/forum?id=n9xeGcI4Yg\n",
      "https://openreview.net/forum?id=JWrl5pJCnl\n",
      "https://openreview.net/forum?id=AZGIwqCyYY\n",
      "https://openreview.net/forum?id=IdibrApfps\n",
      "https://openreview.net/forum?id=9Ik05cycLq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-27 01:24:44,672 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-10-27 01:24:44,743 - INFO - Driver [/Users/yd211/.wdm/drivers/chromedriver/mac64/130.0.6723.69/chromedriver-mac-arm64/chromedriver] found in cache\n",
      "2024-10-27 01:24:45,238 - INFO - Starting scraping for paper: https://openreview.net/forum?id=AOSsLRKQrX\n",
      "2024-10-27 01:24:45,238 - INFO - ====== WebDriver manager ======\n",
      "2024-10-27 01:24:45,241 - INFO - Fetching URL: https://openreview.net/forum?id=AOSsLRKQrX\n",
      "2024-10-27 01:24:45,333 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-10-27 01:24:45,410 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-10-27 01:24:45,473 - INFO - Driver [/Users/yd211/.wdm/drivers/chromedriver/mac64/130.0.6723.69/chromedriver-mac-arm64/chromedriver] found in cache\n",
      "2024-10-27 01:24:45,989 - INFO - Starting scraping for paper: https://openreview.net/forum?id=fMX07g3prp\n",
      "2024-10-27 01:24:45,989 - INFO - ====== WebDriver manager ======\n",
      "2024-10-27 01:24:45,997 - INFO - Fetching URL: https://openreview.net/forum?id=fMX07g3prp\n",
      "2024-10-27 01:24:46,127 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-10-27 01:24:46,294 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-10-27 01:24:46,372 - INFO - Driver [/Users/yd211/.wdm/drivers/chromedriver/mac64/130.0.6723.69/chromedriver-mac-arm64/chromedriver] found in cache\n",
      "2024-10-27 01:24:46,964 - INFO - Starting scraping for paper: https://openreview.net/forum?id=KS8mIvetg2\n",
      "2024-10-27 01:24:46,968 - INFO - ====== WebDriver manager ======\n",
      "2024-10-27 01:24:46,975 - INFO - Fetching URL: https://openreview.net/forum?id=KS8mIvetg2\n",
      "2024-10-27 01:24:47,128 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-10-27 01:24:47,292 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-10-27 01:24:47,364 - INFO - Driver [/Users/yd211/.wdm/drivers/chromedriver/mac64/130.0.6723.69/chromedriver-mac-arm64/chromedriver] found in cache\n",
      "2024-10-27 01:24:48,052 - INFO - Starting scraping for paper: https://openreview.net/forum?id=Re5KnZcXhf\n",
      "2024-10-27 01:24:48,052 - INFO - ====== WebDriver manager ======\n",
      "2024-10-27 01:24:48,058 - INFO - Fetching URL: https://openreview.net/forum?id=Re5KnZcXhf\n",
      "2024-10-27 01:24:48,210 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-10-27 01:24:48,365 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-10-27 01:24:48,436 - INFO - Successfully fetched URL: https://openreview.net/forum?id=AOSsLRKQrX\n",
      "2024-10-27 01:24:48,438 - INFO - Saved HTML to data/iclr_2024/HTML/AOSsLRKQrX.html\n",
      "2024-10-27 01:24:48,457 - INFO - Downloading PDF: https://openreview.net/pdf?id=AOSsLRKQrX\n",
      "2024-10-27 01:24:48,458 - INFO - Driver [/Users/yd211/.wdm/drivers/chromedriver/mac64/130.0.6723.69/chromedriver-mac-arm64/chromedriver] found in cache\n",
      "2024-10-27 01:24:49,064 - INFO - Starting scraping for paper: https://openreview.net/forum?id=JzvIWvC9MG\n",
      "2024-10-27 01:24:49,065 - INFO - ====== WebDriver manager ======\n",
      "2024-10-27 01:24:49,066 - INFO - Fetching URL: https://openreview.net/forum?id=JzvIWvC9MG\n",
      "2024-10-27 01:24:49,168 - INFO - Successfully fetched URL: https://openreview.net/forum?id=fMX07g3prp\n",
      "2024-10-27 01:24:49,172 - INFO - Saved HTML to data/iclr_2024/HTML/fMX07g3prp.html\n",
      "2024-10-27 01:24:49,192 - INFO - Downloading PDF: https://openreview.net/pdf?id=fMX07g3prp\n",
      "2024-10-27 01:24:49,211 - INFO - Downloaded PDF to data/iclr_2024/PDF/AOSsLRKQrX.pdf\n",
      "2024-10-27 01:24:49,220 - INFO - Successfully scraped paper: AOSsLRKQrX\n",
      "2024-10-27 01:24:49,264 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-10-27 01:24:49,509 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-10-27 01:24:49,608 - INFO - Driver [/Users/yd211/.wdm/drivers/chromedriver/mac64/130.0.6723.69/chromedriver-mac-arm64/chromedriver] found in cache\n",
      "2024-10-27 01:24:50,069 - INFO - Downloaded PDF to data/iclr_2024/PDF/fMX07g3prp.pdf\n",
      "2024-10-27 01:24:50,076 - INFO - Successfully scraped paper: fMX07g3prp\n",
      "2024-10-27 01:24:50,198 - INFO - Successfully fetched URL: https://openreview.net/forum?id=KS8mIvetg2\n",
      "2024-10-27 01:24:50,210 - INFO - Saved HTML to data/iclr_2024/HTML/KS8mIvetg2.html\n",
      "2024-10-27 01:24:50,266 - INFO - ====== WebDriver manager ======\n",
      "2024-10-27 01:24:50,277 - INFO - Starting scraping for paper: https://openreview.net/forum?id=WpMHBIYsUf\n",
      "2024-10-27 01:24:50,291 - INFO - Downloading PDF: https://openreview.net/pdf?id=KS8mIvetg2\n",
      "2024-10-27 01:24:50,296 - INFO - Fetching URL: https://openreview.net/forum?id=WpMHBIYsUf\n",
      "2024-10-27 01:24:50,411 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-10-27 01:24:50,490 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-10-27 01:24:50,560 - INFO - Driver [/Users/yd211/.wdm/drivers/chromedriver/mac64/130.0.6723.69/chromedriver-mac-arm64/chromedriver] found in cache\n",
      "2024-10-27 01:24:51,172 - INFO - Successfully fetched URL: https://openreview.net/forum?id=Re5KnZcXhf\n",
      "2024-10-27 01:24:51,187 - INFO - Saved HTML to data/iclr_2024/HTML/Re5KnZcXhf.html\n",
      "2024-10-27 01:24:51,229 - INFO - ====== WebDriver manager ======\n",
      "2024-10-27 01:24:51,238 - INFO - Starting scraping for paper: https://openreview.net/forum?id=My7lkRNnL9\n",
      "2024-10-27 01:24:51,260 - INFO - Downloading PDF: https://openreview.net/pdf?id=Re5KnZcXhf\n",
      "2024-10-27 01:24:51,265 - INFO - Fetching URL: https://openreview.net/forum?id=My7lkRNnL9\n",
      "2024-10-27 01:24:51,296 - INFO - Downloaded PDF to data/iclr_2024/PDF/KS8mIvetg2.pdf\n",
      "2024-10-27 01:24:51,299 - INFO - Successfully scraped paper: KS8mIvetg2\n",
      "2024-10-27 01:24:51,381 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-10-27 01:24:51,533 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-10-27 01:24:51,613 - INFO - Driver [/Users/yd211/.wdm/drivers/chromedriver/mac64/130.0.6723.69/chromedriver-mac-arm64/chromedriver] found in cache\n",
      "2024-10-27 01:24:52,047 - INFO - Downloaded PDF to data/iclr_2024/PDF/Re5KnZcXhf.pdf\n",
      "2024-10-27 01:24:52,048 - INFO - Successfully scraped paper: Re5KnZcXhf\n",
      "2024-10-27 01:24:52,259 - INFO - ====== WebDriver manager ======\n",
      "2024-10-27 01:24:52,259 - INFO - Starting scraping for paper: https://openreview.net/forum?id=dER6OpDTnq\n",
      "2024-10-27 01:24:52,275 - INFO - Fetching URL: https://openreview.net/forum?id=dER6OpDTnq\n",
      "2024-10-27 01:24:52,418 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-10-27 01:24:52,491 - INFO - Successfully fetched URL: https://openreview.net/forum?id=JzvIWvC9MG\n",
      "2024-10-27 01:24:52,494 - INFO - Saved HTML to data/iclr_2024/HTML/JzvIWvC9MG.html\n",
      "2024-10-27 01:24:52,517 - INFO - Downloading PDF: https://openreview.net/pdf?id=JzvIWvC9MG\n",
      "2024-10-27 01:24:52,573 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-10-27 01:24:52,646 - INFO - Driver [/Users/yd211/.wdm/drivers/chromedriver/mac64/130.0.6723.69/chromedriver-mac-arm64/chromedriver] found in cache\n",
      "2024-10-27 01:24:53,227 - INFO - ====== WebDriver manager ======\n",
      "2024-10-27 01:24:53,227 - INFO - Starting scraping for paper: https://openreview.net/forum?id=F2MdnvZl3D\n",
      "2024-10-27 01:24:53,237 - INFO - Fetching URL: https://openreview.net/forum?id=F2MdnvZl3D\n",
      "2024-10-27 01:24:53,308 - INFO - Downloaded PDF to data/iclr_2024/PDF/JzvIWvC9MG.pdf\n",
      "2024-10-27 01:24:53,309 - INFO - Successfully scraped paper: JzvIWvC9MG\n",
      "2024-10-27 01:24:53,353 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-10-27 01:24:53,402 - INFO - Successfully fetched URL: https://openreview.net/forum?id=WpMHBIYsUf\n",
      "2024-10-27 01:24:53,403 - INFO - Saved HTML to data/iclr_2024/HTML/WpMHBIYsUf.html\n",
      "2024-10-27 01:24:53,416 - INFO - Downloading PDF: https://openreview.net/pdf?id=WpMHBIYsUf\n",
      "2024-10-27 01:24:53,521 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-10-27 01:24:53,657 - INFO - Driver [/Users/yd211/.wdm/drivers/chromedriver/mac64/130.0.6723.69/chromedriver-mac-arm64/chromedriver] found in cache\n",
      "2024-10-27 01:24:54,199 - INFO - ====== WebDriver manager ======\n",
      "2024-10-27 01:24:54,199 - INFO - Starting scraping for paper: https://openreview.net/forum?id=mnyXZBa5dP\n",
      "2024-10-27 01:24:54,209 - INFO - Fetching URL: https://openreview.net/forum?id=mnyXZBa5dP\n",
      "2024-10-27 01:24:54,316 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-10-27 01:24:54,358 - INFO - Downloaded PDF to data/iclr_2024/PDF/WpMHBIYsUf.pdf\n",
      "2024-10-27 01:24:54,359 - INFO - Successfully scraped paper: WpMHBIYsUf\n",
      "2024-10-27 01:24:54,408 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-10-27 01:24:54,438 - INFO - Successfully fetched URL: https://openreview.net/forum?id=My7lkRNnL9\n",
      "2024-10-27 01:24:54,439 - INFO - Saved HTML to data/iclr_2024/HTML/My7lkRNnL9.html\n",
      "2024-10-27 01:24:54,455 - INFO - Downloading PDF: https://openreview.net/pdf?id=My7lkRNnL9\n",
      "2024-10-27 01:24:54,488 - INFO - Driver [/Users/yd211/.wdm/drivers/chromedriver/mac64/130.0.6723.69/chromedriver-mac-arm64/chromedriver] found in cache\n",
      "2024-10-27 01:24:55,136 - INFO - ====== WebDriver manager ======\n",
      "2024-10-27 01:24:55,136 - INFO - Starting scraping for paper: https://openreview.net/forum?id=n9xeGcI4Yg\n",
      "2024-10-27 01:24:55,179 - INFO - Fetching URL: https://openreview.net/forum?id=n9xeGcI4Yg\n",
      "2024-10-27 01:24:55,298 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-10-27 01:24:55,430 - INFO - Downloaded PDF to data/iclr_2024/PDF/My7lkRNnL9.pdf\n",
      "2024-10-27 01:24:55,432 - INFO - Successfully scraped paper: My7lkRNnL9\n",
      "2024-10-27 01:24:55,469 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-10-27 01:24:55,715 - INFO - Driver [/Users/yd211/.wdm/drivers/chromedriver/mac64/130.0.6723.69/chromedriver-mac-arm64/chromedriver] found in cache\n",
      "2024-10-27 01:24:56,406 - INFO - ====== WebDriver manager ======\n",
      "2024-10-27 01:24:56,407 - INFO - Starting scraping for paper: https://openreview.net/forum?id=JWrl5pJCnl\n",
      "2024-10-27 01:24:56,418 - INFO - Fetching URL: https://openreview.net/forum?id=JWrl5pJCnl\n",
      "2024-10-27 01:24:56,546 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-10-27 01:24:56,615 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-10-27 01:24:56,790 - INFO - Driver [/Users/yd211/.wdm/drivers/chromedriver/mac64/130.0.6723.69/chromedriver-mac-arm64/chromedriver] found in cache\n",
      "2024-10-27 01:24:57,518 - INFO - Starting scraping for paper: https://openreview.net/forum?id=AZGIwqCyYY\n",
      "2024-10-27 01:24:57,520 - INFO - ====== WebDriver manager ======\n",
      "2024-10-27 01:24:57,535 - INFO - Fetching URL: https://openreview.net/forum?id=AZGIwqCyYY\n",
      "2024-10-27 01:24:57,728 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-10-27 01:24:57,840 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-10-27 01:24:58,089 - INFO - Driver [/Users/yd211/.wdm/drivers/chromedriver/mac64/130.0.6723.69/chromedriver-mac-arm64/chromedriver] found in cache\n",
      "2024-10-27 01:24:58,534 - INFO - Successfully fetched URL: https://openreview.net/forum?id=n9xeGcI4Yg\n",
      "2024-10-27 01:24:58,539 - INFO - Saved HTML to data/iclr_2024/HTML/n9xeGcI4Yg.html\n",
      "2024-10-27 01:24:58,606 - INFO - Starting scraping for paper: https://openreview.net/forum?id=IdibrApfps\n",
      "2024-10-27 01:24:58,613 - INFO - ====== WebDriver manager ======\n",
      "2024-10-27 01:24:58,615 - INFO - Downloading PDF: https://openreview.net/pdf?id=n9xeGcI4Yg\n",
      "2024-10-27 01:24:58,616 - INFO - Fetching URL: https://openreview.net/forum?id=IdibrApfps\n",
      "2024-10-27 01:24:58,723 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-10-27 01:24:59,192 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-10-27 01:24:59,520 - INFO - Driver [/Users/yd211/.wdm/drivers/chromedriver/mac64/130.0.6723.69/chromedriver-mac-arm64/chromedriver] found in cache\n",
      "2024-10-27 01:24:59,655 - INFO - Successfully fetched URL: https://openreview.net/forum?id=JWrl5pJCnl\n",
      "2024-10-27 01:24:59,658 - INFO - Saved HTML to data/iclr_2024/HTML/JWrl5pJCnl.html\n",
      "2024-10-27 01:24:59,698 - INFO - Downloading PDF: https://openreview.net/pdf?id=JWrl5pJCnl\n",
      "2024-10-27 01:25:00,053 - INFO - Starting scraping for paper: https://openreview.net/forum?id=9Ik05cycLq\n",
      "2024-10-27 01:25:00,063 - INFO - Downloaded PDF to data/iclr_2024/PDF/n9xeGcI4Yg.pdf\n",
      "2024-10-27 01:25:00,081 - INFO - Fetching URL: https://openreview.net/forum?id=9Ik05cycLq\n",
      "2024-10-27 01:25:00,087 - INFO - Successfully scraped paper: n9xeGcI4Yg\n",
      "2024-10-27 01:25:01,012 - INFO - Downloaded PDF to data/iclr_2024/PDF/JWrl5pJCnl.pdf\n",
      "2024-10-27 01:25:01,013 - INFO - Successfully scraped paper: JWrl5pJCnl\n",
      "2024-10-27 01:25:01,652 - INFO - Successfully fetched URL: https://openreview.net/forum?id=AZGIwqCyYY\n",
      "2024-10-27 01:25:01,653 - INFO - Saved HTML to data/iclr_2024/HTML/AZGIwqCyYY.html\n",
      "2024-10-27 01:25:01,675 - INFO - Downloading PDF: https://openreview.net/pdf?id=AZGIwqCyYY\n",
      "2024-10-27 01:25:02,999 - INFO - Downloaded PDF to data/iclr_2024/PDF/AZGIwqCyYY.pdf\n",
      "2024-10-27 01:25:03,000 - INFO - Successfully scraped paper: AZGIwqCyYY\n",
      "2024-10-27 01:25:03,514 - INFO - Successfully fetched URL: https://openreview.net/forum?id=9Ik05cycLq\n",
      "2024-10-27 01:25:03,515 - INFO - Saved HTML to data/iclr_2024/HTML/9Ik05cycLq.html\n",
      "2024-10-27 01:25:03,529 - INFO - Downloading PDF: https://openreview.net/pdf?id=9Ik05cycLq\n",
      "2024-10-27 01:25:04,351 - INFO - Downloaded PDF to data/iclr_2024/PDF/9Ik05cycLq.pdf\n",
      "2024-10-27 01:25:04,352 - INFO - Successfully scraped paper: 9Ik05cycLq\n",
      "2024-10-27 01:25:13,363 - ERROR - Timeout while loading https://openreview.net/forum?id=dER6OpDTnq\n",
      "2024-10-27 01:25:13,365 - WARNING - Failed to retrieve HTML for https://openreview.net/forum?id=dER6OpDTnq. Skipping.\n",
      "2024-10-27 01:25:13,886 - ERROR - Timeout while loading https://openreview.net/forum?id=F2MdnvZl3D\n",
      "2024-10-27 01:25:13,886 - WARNING - Failed to retrieve HTML for https://openreview.net/forum?id=F2MdnvZl3D. Skipping.\n",
      "2024-10-27 01:25:15,217 - ERROR - Timeout while loading https://openreview.net/forum?id=mnyXZBa5dP\n",
      "2024-10-27 01:25:15,218 - WARNING - Failed to retrieve HTML for https://openreview.net/forum?id=mnyXZBa5dP. Skipping.\n",
      "2024-10-27 01:25:21,037 - ERROR - Timeout while loading https://openreview.net/forum?id=IdibrApfps\n",
      "2024-10-27 01:25:21,040 - WARNING - Failed to retrieve HTML for https://openreview.net/forum?id=IdibrApfps. Skipping.\n",
      "2024-10-27 01:25:21,231 - INFO - Saved Markdown to data/iclr_2024/Markdown/RzNlECeoOB_metadata.md\n",
      "2024-10-27 01:25:21,231 - INFO - Saved metadata to RzNlECeoOB_metadata.md\n",
      "2024-10-27 01:25:21,232 - INFO - Extracting sections from PDF: data/iclr_2024/PDF/RzNlECeoOB.pdf\n",
      "2024-10-27 01:25:22,441 - INFO - Extracted Abstract and Introduction from data/iclr_2024/PDF/RzNlECeoOB.pdf\n",
      "2024-10-27 01:25:22,442 - INFO - Saved Markdown to data/iclr_2024/Markdown/RzNlECeoOB_sections.md\n",
      "2024-10-27 01:25:22,491 - INFO - Saved Markdown to data/iclr_2024/Markdown/RzNlECeoOB_responses.md\n",
      "2024-10-27 01:25:22,491 - INFO - Saved reviewer responses to RzNlECeoOB_responses.md\n",
      "2024-10-27 01:25:22,491 - INFO - Completed parsing for paper ID: RzNlECeoOB\n",
      "2024-10-27 01:25:22,499 - INFO - Saved Markdown to data/iclr_2024/Markdown/fMX07g3prp_metadata.md\n",
      "2024-10-27 01:25:22,500 - INFO - Saved metadata to fMX07g3prp_metadata.md\n",
      "2024-10-27 01:25:22,500 - INFO - Extracting sections from PDF: data/iclr_2024/PDF/fMX07g3prp.pdf\n",
      "2024-10-27 01:25:23,262 - INFO - Extracted Abstract and Introduction from data/iclr_2024/PDF/fMX07g3prp.pdf\n",
      "2024-10-27 01:25:23,263 - INFO - Saved Markdown to data/iclr_2024/Markdown/fMX07g3prp_sections.md\n",
      "2024-10-27 01:25:23,273 - INFO - Saved Markdown to data/iclr_2024/Markdown/fMX07g3prp_responses.md\n",
      "2024-10-27 01:25:23,273 - INFO - Saved reviewer responses to fMX07g3prp_responses.md\n",
      "2024-10-27 01:25:23,273 - INFO - Completed parsing for paper ID: fMX07g3prp\n",
      "2024-10-27 01:25:23,288 - INFO - Saved Markdown to data/iclr_2024/Markdown/gtkFw6sZGS_metadata.md\n",
      "2024-10-27 01:25:23,288 - INFO - Saved metadata to gtkFw6sZGS_metadata.md\n",
      "2024-10-27 01:25:23,289 - INFO - Extracting sections from PDF: data/iclr_2024/PDF/gtkFw6sZGS.pdf\n",
      "2024-10-27 01:25:24,006 - INFO - Extracted Abstract and Introduction from data/iclr_2024/PDF/gtkFw6sZGS.pdf\n",
      "2024-10-27 01:25:24,007 - INFO - Saved Markdown to data/iclr_2024/Markdown/gtkFw6sZGS_sections.md\n",
      "2024-10-27 01:25:24,042 - INFO - Saved Markdown to data/iclr_2024/Markdown/gtkFw6sZGS_responses.md\n",
      "2024-10-27 01:25:24,043 - INFO - Saved reviewer responses to gtkFw6sZGS_responses.md\n",
      "2024-10-27 01:25:24,043 - INFO - Completed parsing for paper ID: gtkFw6sZGS\n",
      "2024-10-27 01:25:24,056 - INFO - Saved Markdown to data/iclr_2024/Markdown/M6XWoEdmwf_metadata.md\n",
      "2024-10-27 01:25:24,057 - INFO - Saved metadata to M6XWoEdmwf_metadata.md\n",
      "2024-10-27 01:25:24,057 - INFO - Extracting sections from PDF: data/iclr_2024/PDF/M6XWoEdmwf.pdf\n",
      "2024-10-27 01:25:27,056 - INFO - Extracted Abstract and Introduction from data/iclr_2024/PDF/M6XWoEdmwf.pdf\n",
      "2024-10-27 01:25:27,057 - INFO - Saved Markdown to data/iclr_2024/Markdown/M6XWoEdmwf_sections.md\n",
      "2024-10-27 01:25:27,084 - INFO - Saved Markdown to data/iclr_2024/Markdown/M6XWoEdmwf_responses.md\n",
      "2024-10-27 01:25:27,084 - INFO - Saved reviewer responses to M6XWoEdmwf_responses.md\n",
      "2024-10-27 01:25:27,084 - INFO - Completed parsing for paper ID: M6XWoEdmwf\n",
      "2024-10-27 01:25:27,095 - INFO - Saved Markdown to data/iclr_2024/Markdown/KS8mIvetg2_metadata.md\n",
      "2024-10-27 01:25:27,095 - INFO - Saved metadata to KS8mIvetg2_metadata.md\n",
      "2024-10-27 01:25:27,095 - INFO - Extracting sections from PDF: data/iclr_2024/PDF/KS8mIvetg2.pdf\n",
      "2024-10-27 01:25:27,448 - INFO - Extracted Abstract and Introduction from data/iclr_2024/PDF/KS8mIvetg2.pdf\n",
      "2024-10-27 01:25:27,449 - INFO - Saved Markdown to data/iclr_2024/Markdown/KS8mIvetg2_sections.md\n",
      "2024-10-27 01:25:27,463 - INFO - Saved Markdown to data/iclr_2024/Markdown/KS8mIvetg2_responses.md\n",
      "2024-10-27 01:25:27,464 - INFO - Saved reviewer responses to KS8mIvetg2_responses.md\n",
      "2024-10-27 01:25:27,464 - INFO - Completed parsing for paper ID: KS8mIvetg2\n",
      "2024-10-27 01:25:27,472 - INFO - Saved Markdown to data/iclr_2024/Markdown/hxAveMWogn_metadata.md\n",
      "2024-10-27 01:25:27,472 - INFO - Saved metadata to hxAveMWogn_metadata.md\n",
      "2024-10-27 01:25:27,472 - INFO - Extracting sections from PDF: data/iclr_2024/PDF/hxAveMWogn.pdf\n",
      "2024-10-27 01:25:27,843 - INFO - Extracted Abstract and Introduction from data/iclr_2024/PDF/hxAveMWogn.pdf\n",
      "2024-10-27 01:25:27,844 - INFO - Saved Markdown to data/iclr_2024/Markdown/hxAveMWogn_sections.md\n",
      "2024-10-27 01:25:27,852 - INFO - Saved Markdown to data/iclr_2024/Markdown/hxAveMWogn_responses.md\n",
      "2024-10-27 01:25:27,853 - INFO - Saved reviewer responses to hxAveMWogn_responses.md\n",
      "2024-10-27 01:25:27,853 - INFO - Completed parsing for paper ID: hxAveMWogn\n",
      "2024-10-27 01:25:27,869 - INFO - Saved Markdown to data/iclr_2024/Markdown/AZGIwqCyYY_metadata.md\n",
      "2024-10-27 01:25:27,869 - INFO - Saved metadata to AZGIwqCyYY_metadata.md\n",
      "2024-10-27 01:25:27,870 - INFO - Extracting sections from PDF: data/iclr_2024/PDF/AZGIwqCyYY.pdf\n",
      "2024-10-27 01:25:29,853 - INFO - Extracted Abstract and Introduction from data/iclr_2024/PDF/AZGIwqCyYY.pdf\n",
      "2024-10-27 01:25:29,854 - INFO - Saved Markdown to data/iclr_2024/Markdown/AZGIwqCyYY_sections.md\n",
      "2024-10-27 01:25:29,886 - INFO - Saved Markdown to data/iclr_2024/Markdown/AZGIwqCyYY_responses.md\n",
      "2024-10-27 01:25:29,886 - INFO - Saved reviewer responses to AZGIwqCyYY_responses.md\n",
      "2024-10-27 01:25:29,886 - INFO - Completed parsing for paper ID: AZGIwqCyYY\n",
      "2024-10-27 01:25:29,897 - INFO - Saved Markdown to data/iclr_2024/Markdown/RvUVMjfp8i_metadata.md\n",
      "2024-10-27 01:25:29,897 - INFO - Saved metadata to RvUVMjfp8i_metadata.md\n",
      "2024-10-27 01:25:29,897 - INFO - Extracting sections from PDF: data/iclr_2024/PDF/RvUVMjfp8i.pdf\n",
      "2024-10-27 01:25:30,532 - INFO - Extracted Abstract and Introduction from data/iclr_2024/PDF/RvUVMjfp8i.pdf\n",
      "2024-10-27 01:25:30,533 - INFO - Saved Markdown to data/iclr_2024/Markdown/RvUVMjfp8i_sections.md\n",
      "2024-10-27 01:25:30,546 - INFO - Saved Markdown to data/iclr_2024/Markdown/RvUVMjfp8i_responses.md\n",
      "2024-10-27 01:25:30,546 - INFO - Saved reviewer responses to RvUVMjfp8i_responses.md\n",
      "2024-10-27 01:25:30,546 - INFO - Completed parsing for paper ID: RvUVMjfp8i\n",
      "2024-10-27 01:25:30,560 - INFO - Saved Markdown to data/iclr_2024/Markdown/gYcft1HIaU_metadata.md\n",
      "2024-10-27 01:25:30,561 - INFO - Saved metadata to gYcft1HIaU_metadata.md\n",
      "2024-10-27 01:25:30,561 - INFO - Extracting sections from PDF: data/iclr_2024/PDF/gYcft1HIaU.pdf\n",
      "2024-10-27 01:25:30,886 - INFO - Extracted Abstract and Introduction from data/iclr_2024/PDF/gYcft1HIaU.pdf\n",
      "2024-10-27 01:25:30,887 - INFO - Saved Markdown to data/iclr_2024/Markdown/gYcft1HIaU_sections.md\n",
      "2024-10-27 01:25:30,932 - INFO - Saved Markdown to data/iclr_2024/Markdown/gYcft1HIaU_responses.md\n",
      "2024-10-27 01:25:30,932 - INFO - Saved reviewer responses to gYcft1HIaU_responses.md\n",
      "2024-10-27 01:25:30,932 - INFO - Completed parsing for paper ID: gYcft1HIaU\n",
      "2024-10-27 01:25:30,946 - INFO - Saved Markdown to data/iclr_2024/Markdown/JWrl5pJCnl_metadata.md\n",
      "2024-10-27 01:25:30,946 - INFO - Saved metadata to JWrl5pJCnl_metadata.md\n",
      "2024-10-27 01:25:30,946 - INFO - Extracting sections from PDF: data/iclr_2024/PDF/JWrl5pJCnl.pdf\n",
      "2024-10-27 01:25:31,622 - INFO - Extracted Abstract and Introduction from data/iclr_2024/PDF/JWrl5pJCnl.pdf\n",
      "2024-10-27 01:25:31,623 - INFO - Saved Markdown to data/iclr_2024/Markdown/JWrl5pJCnl_sections.md\n",
      "2024-10-27 01:25:31,657 - INFO - Saved Markdown to data/iclr_2024/Markdown/JWrl5pJCnl_responses.md\n",
      "2024-10-27 01:25:31,657 - INFO - Saved reviewer responses to JWrl5pJCnl_responses.md\n",
      "2024-10-27 01:25:31,657 - INFO - Completed parsing for paper ID: JWrl5pJCnl\n",
      "2024-10-27 01:25:31,680 - INFO - Saved Markdown to data/iclr_2024/Markdown/n9xeGcI4Yg_metadata.md\n",
      "2024-10-27 01:25:31,680 - INFO - Saved metadata to n9xeGcI4Yg_metadata.md\n",
      "2024-10-27 01:25:31,680 - INFO - Extracting sections from PDF: data/iclr_2024/PDF/n9xeGcI4Yg.pdf\n",
      "2024-10-27 01:25:32,171 - INFO - Extracted Abstract and Introduction from data/iclr_2024/PDF/n9xeGcI4Yg.pdf\n",
      "2024-10-27 01:25:32,171 - INFO - Saved Markdown to data/iclr_2024/Markdown/n9xeGcI4Yg_sections.md\n",
      "2024-10-27 01:25:32,247 - INFO - Saved Markdown to data/iclr_2024/Markdown/n9xeGcI4Yg_responses.md\n",
      "2024-10-27 01:25:32,247 - INFO - Saved reviewer responses to n9xeGcI4Yg_responses.md\n",
      "2024-10-27 01:25:32,247 - INFO - Completed parsing for paper ID: n9xeGcI4Yg\n",
      "2024-10-27 01:25:32,259 - INFO - Saved Markdown to data/iclr_2024/Markdown/miGpIhquyB_metadata.md\n",
      "2024-10-27 01:25:32,260 - INFO - Saved metadata to miGpIhquyB_metadata.md\n",
      "2024-10-27 01:25:32,260 - INFO - Extracting sections from PDF: data/iclr_2024/PDF/miGpIhquyB.pdf\n",
      "2024-10-27 01:25:33,128 - INFO - Extracted Abstract and Introduction from data/iclr_2024/PDF/miGpIhquyB.pdf\n",
      "2024-10-27 01:25:33,129 - INFO - Saved Markdown to data/iclr_2024/Markdown/miGpIhquyB_sections.md\n",
      "2024-10-27 01:25:33,153 - INFO - Saved Markdown to data/iclr_2024/Markdown/miGpIhquyB_responses.md\n",
      "2024-10-27 01:25:33,153 - INFO - Saved reviewer responses to miGpIhquyB_responses.md\n",
      "2024-10-27 01:25:33,154 - INFO - Completed parsing for paper ID: miGpIhquyB\n",
      "2024-10-27 01:25:33,166 - INFO - Saved Markdown to data/iclr_2024/Markdown/AOSsLRKQrX_metadata.md\n",
      "2024-10-27 01:25:33,166 - INFO - Saved metadata to AOSsLRKQrX_metadata.md\n",
      "2024-10-27 01:25:33,167 - INFO - Extracting sections from PDF: data/iclr_2024/PDF/AOSsLRKQrX.pdf\n",
      "2024-10-27 01:25:33,576 - INFO - Extracted Abstract and Introduction from data/iclr_2024/PDF/AOSsLRKQrX.pdf\n",
      "2024-10-27 01:25:33,577 - INFO - Saved Markdown to data/iclr_2024/Markdown/AOSsLRKQrX_sections.md\n",
      "2024-10-27 01:25:33,599 - INFO - Saved Markdown to data/iclr_2024/Markdown/AOSsLRKQrX_responses.md\n",
      "2024-10-27 01:25:33,599 - INFO - Saved reviewer responses to AOSsLRKQrX_responses.md\n",
      "2024-10-27 01:25:33,599 - INFO - Completed parsing for paper ID: AOSsLRKQrX\n",
      "2024-10-27 01:25:33,613 - INFO - Saved Markdown to data/iclr_2024/Markdown/My7lkRNnL9_metadata.md\n",
      "2024-10-27 01:25:33,613 - INFO - Saved metadata to My7lkRNnL9_metadata.md\n",
      "2024-10-27 01:25:33,613 - INFO - Extracting sections from PDF: data/iclr_2024/PDF/My7lkRNnL9.pdf\n",
      "2024-10-27 01:25:34,676 - INFO - Extracted Abstract and Introduction from data/iclr_2024/PDF/My7lkRNnL9.pdf\n",
      "2024-10-27 01:25:34,677 - INFO - Saved Markdown to data/iclr_2024/Markdown/My7lkRNnL9_sections.md\n",
      "2024-10-27 01:25:34,718 - INFO - Saved Markdown to data/iclr_2024/Markdown/My7lkRNnL9_responses.md\n",
      "2024-10-27 01:25:34,718 - INFO - Saved reviewer responses to My7lkRNnL9_responses.md\n",
      "2024-10-27 01:25:34,718 - INFO - Completed parsing for paper ID: My7lkRNnL9\n",
      "2024-10-27 01:25:34,734 - INFO - Saved Markdown to data/iclr_2024/Markdown/Re5KnZcXhf_metadata.md\n",
      "2024-10-27 01:25:34,734 - INFO - Saved metadata to Re5KnZcXhf_metadata.md\n",
      "2024-10-27 01:25:34,734 - INFO - Extracting sections from PDF: data/iclr_2024/PDF/Re5KnZcXhf.pdf\n",
      "2024-10-27 01:25:35,137 - INFO - Extracted Abstract and Introduction from data/iclr_2024/PDF/Re5KnZcXhf.pdf\n",
      "2024-10-27 01:25:35,138 - INFO - Saved Markdown to data/iclr_2024/Markdown/Re5KnZcXhf_sections.md\n",
      "2024-10-27 01:25:35,187 - INFO - Saved Markdown to data/iclr_2024/Markdown/Re5KnZcXhf_responses.md\n",
      "2024-10-27 01:25:35,188 - INFO - Saved reviewer responses to Re5KnZcXhf_responses.md\n",
      "2024-10-27 01:25:35,188 - INFO - Completed parsing for paper ID: Re5KnZcXhf\n",
      "2024-10-27 01:25:35,198 - INFO - Saved Markdown to data/iclr_2024/Markdown/WpMHBIYsUf_metadata.md\n",
      "2024-10-27 01:25:35,198 - INFO - Saved metadata to WpMHBIYsUf_metadata.md\n",
      "2024-10-27 01:25:35,198 - INFO - Extracting sections from PDF: data/iclr_2024/PDF/WpMHBIYsUf.pdf\n",
      "2024-10-27 01:25:35,833 - INFO - Extracted Abstract and Introduction from data/iclr_2024/PDF/WpMHBIYsUf.pdf\n",
      "2024-10-27 01:25:35,834 - INFO - Saved Markdown to data/iclr_2024/Markdown/WpMHBIYsUf_sections.md\n",
      "2024-10-27 01:25:35,849 - INFO - Saved Markdown to data/iclr_2024/Markdown/WpMHBIYsUf_responses.md\n",
      "2024-10-27 01:25:35,850 - INFO - Saved reviewer responses to WpMHBIYsUf_responses.md\n",
      "2024-10-27 01:25:35,850 - INFO - Completed parsing for paper ID: WpMHBIYsUf\n",
      "2024-10-27 01:25:35,880 - INFO - Saved Markdown to data/iclr_2024/Markdown/9Ik05cycLq_metadata.md\n",
      "2024-10-27 01:25:35,881 - INFO - Saved metadata to 9Ik05cycLq_metadata.md\n",
      "2024-10-27 01:25:35,881 - INFO - Extracting sections from PDF: data/iclr_2024/PDF/9Ik05cycLq.pdf\n",
      "2024-10-27 01:25:36,359 - INFO - Extracted Abstract and Introduction from data/iclr_2024/PDF/9Ik05cycLq.pdf\n",
      "2024-10-27 01:25:36,360 - INFO - Saved Markdown to data/iclr_2024/Markdown/9Ik05cycLq_sections.md\n",
      "2024-10-27 01:25:36,390 - INFO - Saved Markdown to data/iclr_2024/Markdown/9Ik05cycLq_responses.md\n",
      "2024-10-27 01:25:36,391 - INFO - Saved reviewer responses to 9Ik05cycLq_responses.md\n",
      "2024-10-27 01:25:36,391 - INFO - Completed parsing for paper ID: 9Ik05cycLq\n",
      "2024-10-27 01:25:36,416 - INFO - Saved Markdown to data/iclr_2024/Markdown/JzvIWvC9MG_metadata.md\n",
      "2024-10-27 01:25:36,417 - INFO - Saved metadata to JzvIWvC9MG_metadata.md\n",
      "2024-10-27 01:25:36,418 - INFO - Extracting sections from PDF: data/iclr_2024/PDF/JzvIWvC9MG.pdf\n",
      "2024-10-27 01:25:37,695 - INFO - Extracted Abstract and Introduction from data/iclr_2024/PDF/JzvIWvC9MG.pdf\n",
      "2024-10-27 01:25:37,696 - INFO - Saved Markdown to data/iclr_2024/Markdown/JzvIWvC9MG_sections.md\n",
      "2024-10-27 01:25:37,739 - INFO - Saved Markdown to data/iclr_2024/Markdown/JzvIWvC9MG_responses.md\n",
      "2024-10-27 01:25:37,740 - INFO - Saved reviewer responses to JzvIWvC9MG_responses.md\n",
      "2024-10-27 01:25:37,740 - INFO - Completed parsing for paper ID: JzvIWvC9MG\n",
      "2024-10-27 01:25:37,774 - INFO - Saved Markdown to data/iclr_2024/Markdown/5t57omGVMw_metadata.md\n",
      "2024-10-27 01:25:37,774 - INFO - Saved metadata to 5t57omGVMw_metadata.md\n",
      "2024-10-27 01:25:37,774 - INFO - Extracting sections from PDF: data/iclr_2024/PDF/5t57omGVMw.pdf\n",
      "2024-10-27 01:25:38,976 - INFO - Extracted Abstract and Introduction from data/iclr_2024/PDF/5t57omGVMw.pdf\n",
      "2024-10-27 01:25:38,976 - INFO - Saved Markdown to data/iclr_2024/Markdown/5t57omGVMw_sections.md\n",
      "2024-10-27 01:25:39,014 - INFO - Saved Markdown to data/iclr_2024/Markdown/5t57omGVMw_responses.md\n",
      "2024-10-27 01:25:39,014 - INFO - Saved reviewer responses to 5t57omGVMw_responses.md\n",
      "2024-10-27 01:25:39,014 - INFO - Completed parsing for paper ID: 5t57omGVMw\n",
      "2024-10-27 01:25:39,021 - INFO - Aggregated CSV saved to data/iclr_2024/decisions_and_scores.csv\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Scraper for ICLR Papers through OpenReview\n",
    "\n",
    "# %%\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import logging\n",
    "import csv\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import (\n",
    "    TimeoutException,\n",
    "    NoSuchElementException,\n",
    "    ElementNotInteractableException,\n",
    ")\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "from markdownify import markdownify as md\n",
    "from pdfminer.high_level import extract_text\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import glob\n",
    "\n",
    "# %%\n",
    "# Setting up\n",
    "\n",
    "# Configure Logging\n",
    "logging.basicConfig(\n",
    "    filename=\"scraper.log\",\n",
    "    filemode=\"a\",\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "\n",
    "# Also log to console\n",
    "console = logging.StreamHandler()\n",
    "console.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "console.setFormatter(formatter)\n",
    "logging.getLogger().addHandler(console)\n",
    "\n",
    "# Constants\n",
    "BASE_URL = \"https://openreview.net\"\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (compatible; DataScraper/1.0; +https://yourdomain.com/)\"\n",
    "}\n",
    "DOWNLOAD_DIR = \"data/iclr_2024\"\n",
    "HTML_DIR = os.path.join(DOWNLOAD_DIR, \"HTML\")\n",
    "PDF_DIR = os.path.join(DOWNLOAD_DIR, \"PDF\")\n",
    "MARKDOWN_DIR = os.path.join(DOWNLOAD_DIR, \"Markdown\")\n",
    "IMAGES_DIR = os.path.join(DOWNLOAD_DIR, \"Image\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for directory in [DOWNLOAD_DIR, HTML_DIR, PDF_DIR, MARKDOWN_DIR, IMAGES_DIR]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "def setup_selenium():\n",
    "    \"\"\"Sets up Selenium with headless Chrome.\"\"\"\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    \n",
    "    # Initialize Service with ChromeDriver\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    \n",
    "    # Initialize WebDriver with Service and Options\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    return driver\n",
    "\n",
    "def fetch_html(driver, url, timeout=20):\n",
    "    \"\"\"Fetches the fully rendered HTML content of a given URL using Selenium.\"\"\"\n",
    "    try:\n",
    "        logging.info(f\"Fetching URL: {url}\")\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait until the main content is loaded\n",
    "        WebDriverWait(driver, timeout).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"note\"))\n",
    "        )\n",
    "\n",
    "        # Optional: Scroll to the bottom to ensure all lazy-loaded content is fetched\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)  # Wait for additional content to load\n",
    "\n",
    "        html = driver.page_source\n",
    "        logging.info(f\"Successfully fetched URL: {url}\")\n",
    "        return html\n",
    "    except TimeoutException:\n",
    "        logging.error(f\"Timeout while loading {url}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error fetching {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def parse_paper_info(soup):\n",
    "    \"\"\"Parses the paper's BeautifulSoup object to extract metadata.\"\"\"\n",
    "    paper_info = {}\n",
    "\n",
    "    # Extract Title\n",
    "    title_tag = soup.find(\"h2\", class_=\"citation_title\")\n",
    "    paper_info[\"title\"] = title_tag.text.strip() if title_tag else \"N/A\"\n",
    "\n",
    "    # Extract Authors\n",
    "    authors_tag = soup.find(\"div\", class_=\"forum-authors\")\n",
    "    if authors_tag:\n",
    "        authors = [author.text.strip() for author in authors_tag.find_all(\"a\")]\n",
    "        paper_info[\"authors\"] = authors\n",
    "    else:\n",
    "        paper_info[\"authors\"] = []\n",
    "\n",
    "    # Extract Publication Date\n",
    "    pub_date_tag = soup.find(\"span\", class_=\"glyphicon-calendar\")\n",
    "    if pub_date_tag and pub_date_tag.parent:\n",
    "        dates_text = pub_date_tag.parent.text.strip()\n",
    "        publication_date = re.search(r\"Published:\\s*(.*?)(?:,|$)\", dates_text)\n",
    "        paper_info[\"publication_date\"] = (\n",
    "            publication_date.group(1) if publication_date else \"N/A\"\n",
    "        )\n",
    "    else:\n",
    "        paper_info[\"publication_date\"] = \"N/A\"\n",
    "\n",
    "    # Extract PDF URL\n",
    "    pdf_link_tag = soup.find(\"a\", class_=\"citation_pdf_url\")\n",
    "    if pdf_link_tag and \"href\" in pdf_link_tag.attrs:\n",
    "        pdf_url = pdf_link_tag[\"href\"]\n",
    "        if not pdf_url.startswith(\"http\"):\n",
    "            pdf_url = BASE_URL + pdf_url\n",
    "        paper_info[\"pdf_url\"] = pdf_url\n",
    "    else:\n",
    "        paper_info[\"pdf_url\"] = None\n",
    "\n",
    "    return paper_info\n",
    "\n",
    "def download_pdf(pdf_url, save_path):\n",
    "    \"\"\"Downloads the PDF from the given URL to the specified path.\"\"\"\n",
    "    try:\n",
    "        logging.info(f\"Downloading PDF: {pdf_url}\")\n",
    "        response = requests.get(pdf_url, headers=HEADERS)\n",
    "        response.raise_for_status()\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        logging.info(f\"Downloaded PDF to {save_path}\")\n",
    "        return True\n",
    "    except requests.RequestException as e:\n",
    "        logging.error(f\"Error downloading PDF from {pdf_url}: {e}\")\n",
    "        return False\n",
    "\n",
    "def extract_sections_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts the abstract and introduction from the PDF.\"\"\"\n",
    "    try:\n",
    "        logging.info(f\"Extracting sections from PDF: {pdf_path}\")\n",
    "        text = extract_text(pdf_path)\n",
    "        # Normalize whitespace\n",
    "        text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "        # Improved regex patterns to accurately capture Abstract and Introduction\n",
    "        abstract_match = re.search(\n",
    "            r\"(?is)abstract\\s*(.*?)\\s*(?:(introduction|1\\.\\s*Introduction|2\\.\\s*Methods|methods|conclusion|related work|acknowledgments|references|$))\",\n",
    "            text\n",
    "        )\n",
    "        introduction_match = re.search(\n",
    "            r\"(?is)(introduction|1\\.\\s*Introduction)\\s*(.*?)\\s*(?:(conclusion|related work|methods|acknowledgments|references|2\\.\\s*Methods|$))\",\n",
    "            text\n",
    "        )\n",
    "\n",
    "        abstract = abstract_match.group(1).strip() if abstract_match else \"N/A\"\n",
    "        introduction = introduction_match.group(2).strip() if introduction_match else \"N/A\"\n",
    "\n",
    "        logging.info(f\"Extracted Abstract and Introduction from {pdf_path}\")\n",
    "        return abstract, introduction\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error extracting text from PDF {pdf_path}: {e}\")\n",
    "        return \"N/A\", \"N/A\"\n",
    "\n",
    "def convert_to_markdown(text, header):\n",
    "    \"\"\"Converts plain text to Markdown with a specified header.\"\"\"\n",
    "    if text == \"N/A\":\n",
    "        markdown = f\"## {header}\\n\\nN/A\\n\"\n",
    "    else:\n",
    "        markdown = f\"## {header}\\n\\n{text}\\n\"\n",
    "    return markdown\n",
    "\n",
    "def save_markdown(content, filename):\n",
    "    \"\"\"Saves the given content to a Markdown file.\"\"\"\n",
    "    try:\n",
    "        path = os.path.join(MARKDOWN_DIR, filename)\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(content)\n",
    "        logging.info(f\"Saved Markdown to {path}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error saving Markdown file {filename}: {e}\")\n",
    "\n",
    "def extract_reviewer_responses(soup):\n",
    "    \"\"\"Extracts all notes (reviews, meta-reviews, decisions, comments) in order.\"\"\"\n",
    "    responses = []\n",
    "\n",
    "    # Find all notes (reviews, meta-reviews, decisions, comments)\n",
    "    note_divs = soup.find_all(\"div\", class_=\"note\", attrs={\"data-id\": re.compile(\".*\")})\n",
    "\n",
    "    for note in note_divs:\n",
    "        # Determine the type of note\n",
    "        invitation = note.find(\"span\", class_=\"invitation\")\n",
    "        if not invitation:\n",
    "            continue\n",
    "        invitation_type = invitation.text.strip()\n",
    "\n",
    "        # Extract author\n",
    "        signatures_span = note.find(\"span\", class_=\"signatures\")\n",
    "        author = \"N/A\"\n",
    "        if signatures_span:\n",
    "            author_tags = signatures_span.find_all(\"span\")\n",
    "            if author_tags:\n",
    "                author = author_tags[-1].text.strip()\n",
    "            else:\n",
    "                author = signatures_span.text.strip()\n",
    "\n",
    "        # Extract content fields\n",
    "        content_div = note.find(\"div\", class_=\"note-content\")\n",
    "        content_dict = {}\n",
    "        if content_div:\n",
    "            content_fields = content_div.find_all(\"div\", recursive=False)\n",
    "            for field in content_fields:\n",
    "                field_name_tag = field.find(\"strong\", class_=\"note-content-field\")\n",
    "                if not field_name_tag:\n",
    "                    continue\n",
    "                field_name = field_name_tag.text.strip(\":\").strip()\n",
    "                field_value_div = field.find(\"div\", class_=\"note-content-value\")\n",
    "                field_value_span = field.find(\"span\", class_=\"note-content-value\")\n",
    "                field_value = \"\"\n",
    "                if field_value_div:\n",
    "                    field_value = md(str(field_value_div)).strip()\n",
    "                elif field_value_span:\n",
    "                    field_value = md(str(field_value_span)).strip()\n",
    "                content_dict[field_name] = field_value\n",
    "\n",
    "        # Determine the note type\n",
    "        if \"Soundness\" in content_dict:\n",
    "            note_type = \"Official Review\"\n",
    "        else:\n",
    "            note_type = invitation_type  # Use the invitation type as the note type\n",
    "\n",
    "        # Append the note\n",
    "        responses.append(\n",
    "            {\"type\": note_type, \"author\": author, \"content\": content_dict}\n",
    "        )\n",
    "\n",
    "        # Handle nested comments (e.g., author responses)\n",
    "        nested_comments = note.find_all(\n",
    "            \"div\", class_=\"note\", attrs={\"data-id\": re.compile(\".*\")}\n",
    "        )\n",
    "        for comment in nested_comments:\n",
    "            comment_invitation = comment.find(\"span\", class_=\"invitation\")\n",
    "            if comment_invitation:\n",
    "                comment_type = comment_invitation.text.strip()\n",
    "                comment_author_span = comment.find(\"span\", class_=\"signatures\")\n",
    "                comment_author = \"N/A\"\n",
    "                if comment_author_span:\n",
    "                    author_tags = comment_author_span.find_all(\"span\")\n",
    "                    if author_tags:\n",
    "                        comment_author = author_tags[-1].text.strip()\n",
    "                    else:\n",
    "                        comment_author = comment_author_span.text.strip()\n",
    "\n",
    "                comment_content_div = comment.find(\"div\", class_=\"note-content\")\n",
    "                comment_content_dict = {}\n",
    "                if comment_content_div:\n",
    "                    content_fields = comment_content_div.find_all(\"div\", recursive=False)\n",
    "                    for field in content_fields:\n",
    "                        field_name_tag = field.find(\"strong\", class_=\"note-content-field\")\n",
    "                        if not field_name_tag:\n",
    "                            continue\n",
    "                        field_name = field_name_tag.text.strip(\":\").strip()\n",
    "                        field_value_div = field.find(\"div\", class_=\"note-content-value\")\n",
    "                        field_value_span = field.find(\"span\", class_=\"note-content-value\")\n",
    "                        field_value = \"\"\n",
    "                        if field_value_div:\n",
    "                            field_value = md(str(field_value_div)).strip()\n",
    "                        elif field_value_span:\n",
    "                            field_value = md(str(field_value_span)).strip()\n",
    "                        comment_content_dict[field_name] = field_value\n",
    "\n",
    "                responses.append(\n",
    "                    {\"type\": comment_type, \"author\": comment_author, \"content\": comment_content_dict}\n",
    "                )\n",
    "\n",
    "    return responses\n",
    "\n",
    "\n",
    "def save_reviewer_responses(responses, filename):\n",
    "    \"\"\"Saves reviewer responses to a Markdown file, maintaining the sequential order.\"\"\"\n",
    "    try:\n",
    "        content = f\"## Reviewer Responses\\n\\n\"\n",
    "        for idx, response in enumerate(responses, 1):\n",
    "            content += f\"### {response['type']} {idx}\\n\"\n",
    "            content += f\"**Author:** {response['author']}\\n\\n\"\n",
    "            for field_name, field_value in response[\"content\"].items():\n",
    "                content += f\"**{field_name}:**\\n{field_value}\\n\\n\"\n",
    "            content += \"\\n\"\n",
    "        save_markdown(content, filename)\n",
    "        logging.info(f\"Saved reviewer responses to {filename}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error saving reviewer responses to {filename}: {e}\")\n",
    "\n",
    "\n",
    "def save_paper_metadata(paper_info, filename):\n",
    "    \"\"\"Saves paper metadata to a Markdown file.\"\"\"\n",
    "    try:\n",
    "        content = f\"# {paper_info['title']}\\n\\n\"\n",
    "        content += f\"**Authors:** {', '.join(paper_info['authors'])}\\n\\n\"\n",
    "        content += f\"**Publication Date:** {paper_info['publication_date']}\\n\\n\"\n",
    "        save_markdown(content, filename)\n",
    "        logging.info(f\"Saved metadata to {filename}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error saving metadata to {filename}: {e}\")\n",
    "\n",
    "def scrape_paper(driver, paper_url):\n",
    "    \"\"\"Scrapes a single paper: downloads HTML and PDF.\"\"\"\n",
    "    logging.info(f\"Starting scraping for paper: {paper_url}\")\n",
    "    html = fetch_html(driver, paper_url)\n",
    "    if not html:\n",
    "        logging.warning(f\"Failed to retrieve HTML for {paper_url}. Skipping.\")\n",
    "        return\n",
    "    \n",
    "    paper_id_match = re.search(r\"id=(.+)\", paper_url)\n",
    "    paper_id = paper_id_match.group(1) if paper_id_match else \"unknown\"\n",
    "    \n",
    "    # Save HTML\n",
    "    html_filename = os.path.join(HTML_DIR, f\"{paper_id}.html\")\n",
    "    try:\n",
    "        with open(html_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(html)\n",
    "        logging.info(f\"Saved HTML to {html_filename}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error saving HTML for {paper_url}: {e}\")\n",
    "    \n",
    "    # Parse paper info to get PDF URL\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    paper_info = parse_paper_info(soup)\n",
    "    \n",
    "    # Download PDF\n",
    "    if paper_info[\"pdf_url\"]:\n",
    "        pdf_filename = f\"{paper_id}.pdf\"\n",
    "        pdf_path = os.path.join(PDF_DIR, pdf_filename)\n",
    "        success = download_pdf(paper_info[\"pdf_url\"], pdf_path)\n",
    "        if success:\n",
    "            logging.info(f\"Successfully scraped paper: {paper_id}\")\n",
    "    else:\n",
    "        logging.warning(f\"No PDF URL found for {paper_url}.\")\n",
    "\n",
    "def parse_paper(paper_id):\n",
    "    \"\"\"Parses the scraped HTML and PDF to extract metadata, sections, and reviewer responses.\"\"\"\n",
    "    html_filename = os.path.join(HTML_DIR, f\"{paper_id}.html\")\n",
    "    pdf_path = os.path.join(PDF_DIR, f\"{paper_id}.pdf\")\n",
    "    \n",
    "    # Read HTML\n",
    "    try:\n",
    "        with open(html_filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            html = f.read()\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error reading HTML file {html_filename}: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Parse paper info\n",
    "    paper_info = parse_paper_info(soup)\n",
    "    \n",
    "    # Save metadata\n",
    "    metadata_filename = f\"{paper_id}_metadata.md\"\n",
    "    save_paper_metadata(paper_info, metadata_filename)\n",
    "    \n",
    "    # Extract sections from PDF\n",
    "    if os.path.exists(pdf_path):\n",
    "        abstract, introduction = extract_sections_from_pdf(pdf_path)\n",
    "        abstract_md = convert_to_markdown(abstract, \"Abstract\")\n",
    "        introduction_md = convert_to_markdown(introduction, \"Introduction\")\n",
    "        combined_md = abstract_md + \"\\n\" + introduction_md\n",
    "        sections_filename = f\"{paper_id}_sections.md\"\n",
    "        save_markdown(combined_md, sections_filename)\n",
    "    else:\n",
    "        logging.warning(f\"PDF not found for paper ID {paper_id}. Skipping section extraction.\")\n",
    "    \n",
    "    # Extract reviewer responses\n",
    "    responses = extract_reviewer_responses(soup)\n",
    "    if responses:\n",
    "        responses_filename = f\"{paper_id}_responses.md\"\n",
    "        save_reviewer_responses(responses, responses_filename)\n",
    "    else:\n",
    "        logging.info(f\"No reviewer responses found for paper ID {paper_id}.\")\n",
    "    \n",
    "    logging.info(f\"Completed parsing for paper ID: {paper_id}\")\n",
    "\n",
    "def aggregate_csv(csv_filename=\"decisions_and_scores.csv\"):\n",
    "    \"\"\"Aggregates decisions and scores from all *_responses.md files into a CSV.\"\"\"\n",
    "    csv_path = os.path.join(DOWNLOAD_DIR, csv_filename)\n",
    "    fieldnames = [\"paperid\", \"title\", \"decision\", \"soundness\", \"presentation\", \"contribution\", \"review_rating\", \"confidence\"]\n",
    "\n",
    "    try:\n",
    "        with open(csv_path, \"w\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            \n",
    "            # Get all responses.md files\n",
    "            responses_files = glob.glob(os.path.join(MARKDOWN_DIR, \"*_responses.md\"))\n",
    "            for resp_file in responses_files:\n",
    "                paper_id = os.path.basename(resp_file).replace(\"_responses.md\", \"\")\n",
    "                metadata_file = os.path.join(MARKDOWN_DIR, f\"{paper_id}_metadata.md\")\n",
    "                \n",
    "                # Read metadata to get title\n",
    "                try:\n",
    "                    with open(metadata_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                        metadata = f.read()\n",
    "                    title_match = re.search(r\"# (.+)\", metadata)\n",
    "                    title = title_match.group(1).strip() if title_match else \"N/A\"\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error reading metadata for {paper_id}: {e}\")\n",
    "                    title = \"N/A\"\n",
    "                \n",
    "                # Initialize lists\n",
    "                decision = \"N/A\"\n",
    "                soundness_list = []\n",
    "                presentation_list = []\n",
    "                contribution_list = []\n",
    "                rating_list = []\n",
    "                confidence_list = []\n",
    "                \n",
    "                # Read responses to get decision and reviews\n",
    "                try:\n",
    "                    with open(resp_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                        responses_md = f.read()\n",
    "                    \n",
    "                    # Split the responses_md into sections\n",
    "                    sections = re.split(r\"^### \", responses_md, flags=re.MULTILINE)\n",
    "                    for section in sections:\n",
    "                        if not section.strip():\n",
    "                            continue\n",
    "                        header_match = re.match(r\"(\\w+.*?)\\n\", section)\n",
    "                        if header_match:\n",
    "                            header = header_match.group(1).strip()\n",
    "                            content = section[header_match.end():]\n",
    "                            if header.startswith(\"Decision\"):\n",
    "                                # Extract decision\n",
    "                                decision_match = re.search(r\"\\*\\*Decision:\\*\\*\\s*\\n*(.+?)(?:\\n\\n|\\Z)\", content, re.DOTALL)\n",
    "                                decision = decision_match.group(1).strip() if decision_match else \"N/A\"\n",
    "                            elif header.startswith(\"Official Review\"):\n",
    "                                # Extract review fields\n",
    "                                soundness = re.search(r\"\\*\\*Soundness:\\*\\*\\s*(\\d+)\", content, re.IGNORECASE)\n",
    "                                presentation = re.search(r\"\\*\\*Presentation:\\*\\*\\s*(\\d+)\", content, re.IGNORECASE)\n",
    "                                contribution = re.search(r\"\\*\\*Contribution:\\*\\*\\s*(\\d+)\", content, re.IGNORECASE)\n",
    "                                rating = re.search(r\"\\*\\*Rating:\\*\\*\\s*(\\d+)\", content, re.IGNORECASE)\n",
    "                                confidence = re.search(r\"\\*\\*Confidence:\\*\\*\\s*(\\d+)\", content, re.IGNORECASE)\n",
    "                                \n",
    "                                soundness_list.append(soundness.group(1) if soundness else \"N/A\")\n",
    "                                presentation_list.append(presentation.group(1) if presentation else \"N/A\")\n",
    "                                contribution_list.append(contribution.group(1) if contribution else \"N/A\")\n",
    "                                rating_list.append(rating.group(1) if rating else \"N/A\")\n",
    "                                confidence_list.append(confidence.group(1) if confidence else \"N/A\")\n",
    "                            else:\n",
    "                                # Other types, ignore for CSV\n",
    "                                pass\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error reading responses for {paper_id}: {e}\")\n",
    "                \n",
    "                # Compile row data\n",
    "                row = {\n",
    "                    \"paperid\": paper_id,\n",
    "                    \"title\": title,\n",
    "                    \"decision\": decision,\n",
    "                    \"soundness\": str(soundness_list),\n",
    "                    \"presentation\": str(presentation_list),\n",
    "                    \"contribution\": str(contribution_list),\n",
    "                    \"review_rating\": str(rating_list),\n",
    "                    \"confidence\": str(confidence_list)\n",
    "                }\n",
    "                \n",
    "                # Write to CSV\n",
    "                writer.writerow(row)\n",
    "        \n",
    "        logging.info(f\"Aggregated CSV saved to {csv_path}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error creating CSV file {csv_path}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_papers_parallel_scrape(paper_urls, max_workers=4):\n",
    "    \"\"\"Processes multiple papers in parallel for scraping.\"\"\"\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = []\n",
    "        for url in paper_urls:\n",
    "            driver = setup_selenium()\n",
    "            future = executor.submit(scrape_paper, driver, url)\n",
    "            futures.append((future, driver))\n",
    "\n",
    "        for future, driver in futures:\n",
    "            try:\n",
    "                future.result()\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error scraping a paper: {e}\")\n",
    "            finally:\n",
    "                driver.quit()\n",
    "\n",
    "def process_all_papers_parsing():\n",
    "    \"\"\"Parses all scraped papers.\"\"\"\n",
    "    html_files = glob.glob(os.path.join(HTML_DIR, \"*.html\"))\n",
    "    for html_file in html_files:\n",
    "        paper_id = os.path.basename(html_file).replace(\".html\", \"\")\n",
    "        parse_paper(paper_id)\n",
    "\n",
    "def run_aggregation():\n",
    "    \"\"\"Runs the CSV aggregation after parsing.\"\"\"\n",
    "    aggregate_csv()\n",
    "\n",
    "def get_paper_urls_from_page(driver, page_url):\n",
    "    \"\"\"Extract all unique paper URLs from the given OpenReview page.\"\"\"\n",
    "    driver.get(page_url)\n",
    "    time.sleep(3)  # Give some time for page to load (adjust as necessary)\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    paper_links = soup.find_all(\"a\", href=True)\n",
    "\n",
    "    # Filter out URLs with '&noteId=' and ensure they contain 'forum?id='\n",
    "    paper_urls = [\n",
    "        link[\"href\"]\n",
    "        for link in paper_links\n",
    "        if \"forum?id=\" in link[\"href\"] and \"&noteId=\" not in link[\"href\"]\n",
    "    ]\n",
    "\n",
    "    return paper_urls\n",
    "\n",
    "def url_getter():\n",
    "    base_url = \"https://openreview.net/group?id=ICLR.cc/2024/Conference\"  # The URL of the OpenReview ICLR page\n",
    "    driver = setup_selenium()\n",
    "\n",
    "    all_paper_urls = []\n",
    "\n",
    "    # Modify the range as needed to scrape multiple pages\n",
    "    for page_number in range(1):\n",
    "        page_url = f\"{base_url}&page={page_number}\"\n",
    "        paper_urls = get_paper_urls_from_page(driver, page_url)\n",
    "        all_paper_urls.extend(paper_urls)\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    # Create a list with the desired format\n",
    "    unique_urls = list(set(all_paper_urls))\n",
    "    # For prototyping, limit to first 5 papers\n",
    "    formatted_urls = [f\"https://openreview.net{url}\" for url in unique_urls[:15]]\n",
    "\n",
    "    return formatted_urls\n",
    "\n",
    "# %%\n",
    "# Experimenting with the scraper\n",
    "\n",
    "# Initial list of paper URLs (you can comment this out if using url_getter)\n",
    "# paper_urls = [\n",
    "#     \"https://openreview.net/forum?id=KS8mIvetg2\",\n",
    "#     \"https://openreview.net/forum?id=7Ttk3RzDeu\",\n",
    "#     \"https://openreview.net/forum?id=ANvmVS2Yr0\",\n",
    "#     \"https://openreview.net/forum?id=ekeyCgeRfC\",\n",
    "# ]\n",
    "\n",
    "# Alternatively, get paper URLs from the OpenReview page\n",
    "paper_urls = url_getter()\n",
    "print('\\n'.join(paper_urls))\n",
    "process_papers_parallel_scrape(paper_urls, max_workers=8)\n",
    "\n",
    "# %%\n",
    "# After scraping, parse all papers and aggregate CSV\n",
    "process_all_papers_parsing()\n",
    "aggregate_csv()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
